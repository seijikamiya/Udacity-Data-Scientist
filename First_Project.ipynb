{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What percentage of developers are satisfied with their job?\n",
    "I have used machine learning to analyze which factors have influenced the outcome of the Stack Overflow Survey for 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import optuna.integration.lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv data and confirm the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64461, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent</th>\n",
       "      <th>MainBranch</th>\n",
       "      <th>Hobbyist</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age1stCode</th>\n",
       "      <th>CompFreq</th>\n",
       "      <th>CompTotal</th>\n",
       "      <th>ConvertedComp</th>\n",
       "      <th>Country</th>\n",
       "      <th>CurrencyDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>SurveyEase</th>\n",
       "      <th>SurveyLength</th>\n",
       "      <th>Trans</th>\n",
       "      <th>UndergradMajor</th>\n",
       "      <th>WebframeDesireNextYear</th>\n",
       "      <th>WebframeWorkedWith</th>\n",
       "      <th>WelcomeChange</th>\n",
       "      <th>WorkWeekHrs</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>YearsCodePro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>European Euro</td>\n",
       "      <td>...</td>\n",
       "      <td>Neither easy nor difficult</td>\n",
       "      <td>Appropriate in length</td>\n",
       "      <td>No</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>ASP.NET Core</td>\n",
       "      <td>ASP.NET;ASP.NET Core</td>\n",
       "      <td>Just as welcome now as I felt last year</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Pound sterling</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Somewhat more welcome now than last year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I code primarily as a hobby</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Neither easy nor difficult</td>\n",
       "      <td>Appropriate in length</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Somewhat more welcome now than last year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Albanian lek</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Somewhat less welcome now than last year</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I used to be a developer by profession, but no...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Too short</td>\n",
       "      <td>No</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>Django;Ruby on Rails</td>\n",
       "      <td>Ruby on Rails</td>\n",
       "      <td>Just as welcome now as I felt last year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Respondent                                         MainBranch Hobbyist  \\\n",
       "0           1                     I am a developer by profession      Yes   \n",
       "1           2                     I am a developer by profession       No   \n",
       "2           3                        I code primarily as a hobby      Yes   \n",
       "3           4                     I am a developer by profession      Yes   \n",
       "4           5  I used to be a developer by profession, but no...      Yes   \n",
       "\n",
       "    Age Age1stCode CompFreq  CompTotal  ConvertedComp             Country  \\\n",
       "0   NaN         13  Monthly        NaN            NaN             Germany   \n",
       "1   NaN         19      NaN        NaN            NaN      United Kingdom   \n",
       "2   NaN         15      NaN        NaN            NaN  Russian Federation   \n",
       "3  25.0         18      NaN        NaN            NaN             Albania   \n",
       "4  31.0         16      NaN        NaN            NaN       United States   \n",
       "\n",
       "     CurrencyDesc  ...                  SurveyEase           SurveyLength  \\\n",
       "0   European Euro  ...  Neither easy nor difficult  Appropriate in length   \n",
       "1  Pound sterling  ...                         NaN                    NaN   \n",
       "2             NaN  ...  Neither easy nor difficult  Appropriate in length   \n",
       "3    Albanian lek  ...                         NaN                    NaN   \n",
       "4             NaN  ...                        Easy              Too short   \n",
       "\n",
       "  Trans                                     UndergradMajor  \\\n",
       "0    No  Computer science, computer engineering, or sof...   \n",
       "1   NaN  Computer science, computer engineering, or sof...   \n",
       "2   NaN                                                NaN   \n",
       "3    No  Computer science, computer engineering, or sof...   \n",
       "4    No  Computer science, computer engineering, or sof...   \n",
       "\n",
       "  WebframeDesireNextYear    WebframeWorkedWith  \\\n",
       "0           ASP.NET Core  ASP.NET;ASP.NET Core   \n",
       "1                    NaN                   NaN   \n",
       "2                    NaN                   NaN   \n",
       "3                    NaN                   NaN   \n",
       "4   Django;Ruby on Rails         Ruby on Rails   \n",
       "\n",
       "                              WelcomeChange WorkWeekHrs YearsCode YearsCodePro  \n",
       "0   Just as welcome now as I felt last year        50.0        36           27  \n",
       "1  Somewhat more welcome now than last year         NaN         7            4  \n",
       "2  Somewhat more welcome now than last year         NaN         4          NaN  \n",
       "3  Somewhat less welcome now than last year        40.0         7            4  \n",
       "4   Just as welcome now as I felt last year         NaN        15            8  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Stack Overflow survey 2020 data\n",
    "df = pd.read_csv('./developer_survey_2020/survey_results_public.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Number of responses by country\n",
    "df_country = df[\"Country\"].value_counts()[:10]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 8));\n",
    "df_country.plot.bar(ax=ax);\n",
    "ax.set_ylabel(\"Number of responses\", fontdict={'size':18});\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0);\n",
    "ax.set_xlabel(\"Country\", fontdict={'size': 18});\n",
    "ax.tick_params(axis='both', labelsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004635410163565988"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percentage of responses from Japan\n",
    "df_country_persentage = df[\"Country\"].value_counts(normalize=True)\n",
    "df_country_persentage['Japan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make pie chart to find what percentage of developers are satisfied with their job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to make pie chart\n",
    "def make_pie_chart(df):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe\n",
    "    \n",
    "    OUTPUT\n",
    "    pie chart\n",
    "    '''\n",
    "    table = { key: (df['JobSat']==key).sum() for key in set(df['JobSat'])} \n",
    "    values = [table[\"Very satisfied\"], table[\"Slightly satisfied\"], table[\"Neither satisfied nor dissatisfied\"], table[\"Slightly dissatisfied\"], table[\"Very dissatisfied\"]]\n",
    "    label = [\"Very satisfied\", \"Slightly satisfied\", \"Neither satisfied nor dissatisfied\", \"Slightly dissatisfied\", \"Very dissatisfied\"]\n",
    "    plt.pie(values,\n",
    "           labels=label, counterclock=False, startangle=90,\n",
    "           autopct='%1.1f%%', pctdistance=0.7)\n",
    "    plt.savefig(\"pie_chart.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "make_pie_chart(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10349\\anaconda3\\envs\\avilen\\lib\\site-packages\\pandas\\core\\series.py:4523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "C:\\Users\\10349\\anaconda3\\envs\\avilen\\lib\\site-packages\\ipykernel\\__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe \n",
    "    \n",
    "    OUTPUT\n",
    "    X - A matrix holding all of the variables you want to consider when predicting the response\n",
    "    y - the corresponding response vector\n",
    "    \n",
    "    This function cleans df using the following steps to produce X and y:\n",
    "    1. Drop all the rows with no 'JobSat'\n",
    "    2. Create y as the 'JobSat' column\n",
    "    3. Change 'JobSat' data from string to value (LabelEncoder)\n",
    "    4. For each numeric variable in df, fill the column with the mean value of the column.\n",
    "    5. Create dummy columns for all the categorical variables in df, drop the original columns\n",
    "    6.Create X as all the columns that are not the 'JobSat' and ' Respondent' column\n",
    "    '''\n",
    "    le = LabelEncoder()    \n",
    "    \n",
    "    # Drop rows with missing 'JobSat'\n",
    "    df = df.dropna(subset=['JobSat'], axis=0)\n",
    "    \n",
    "    #Create y as the'JobSat' column\n",
    "    df_JobSat = df['JobSat']\n",
    "    \n",
    "    #LabelEncoder\n",
    "    le.fit(df_JobSat)\n",
    "    y = le.transform(df_JobSat)\n",
    "    \n",
    "    # Fill numeric columns with the mean\n",
    "    num_vars = df.select_dtypes(include=['float', 'int']).columns\n",
    "    for col in num_vars:\n",
    "        df[col].fillna((df[col].mean()), inplace=True)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    # The categorical variables to the label\n",
    "    cat_vars = df.select_dtypes(include=['object']).copy().columns\n",
    "    for var in  cat_vars:\n",
    "        #LabelEncoder\n",
    "        le.fit(df[var])\n",
    "        df[var] = le.transform(df[var])\n",
    "    \n",
    "    X = df.drop(['JobSat', 'Respondent'], axis=1)\n",
    "    return X, y\n",
    "    \n",
    "#Use the function to create X and y\n",
    "X, y = clean_data(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-23 23:24:21,319]\u001b[0m A new study created in memory with name: no-name-8c7de336-a4ce-4379-86ba-5dfa3fb2808f\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|                                                                                | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.46523\tvalid's multi_logloss: 1.46696\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.4434\tvalid's multi_logloss: 1.44986\n",
      "[3]\ttrain's multi_logloss: 1.43093\tvalid's multi_logloss: 1.44122\n",
      "[4]\ttrain's multi_logloss: 1.41546\tvalid's multi_logloss: 1.4298\n",
      "[5]\ttrain's multi_logloss: 1.39934\tvalid's multi_logloss: 1.41716\n",
      "[6]\ttrain's multi_logloss: 1.38613\tvalid's multi_logloss: 1.40744\n",
      "[7]\ttrain's multi_logloss: 1.37551\tvalid's multi_logloss: 1.40041\n",
      "[8]\ttrain's multi_logloss: 1.3647\tvalid's multi_logloss: 1.39338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.383802:  14%|#########5                                                         | 1/7 [00:00<00:02,  2.15it/s]\u001b[32m[I 2021-03-23 23:24:21,792]\u001b[0m Trial 0 finished with value: 1.3838018421928033 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 1.3838018421928033.\u001b[0m\n",
      "feature_fraction, val_score: 1.383802:  14%|#########5                                                         | 1/7 [00:00<00:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttrain's multi_logloss: 1.35708\tvalid's multi_logloss: 1.38902\n",
      "[10]\ttrain's multi_logloss: 1.34867\tvalid's multi_logloss: 1.3838\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.34867\tvalid's multi_logloss: 1.3838\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.47365\tvalid's multi_logloss: 1.47487\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.45072\tvalid's multi_logloss: 1.45613\n",
      "[3]\ttrain's multi_logloss: 1.43851\tvalid's multi_logloss: 1.44747\n",
      "[4]\ttrain's multi_logloss: 1.42391\tvalid's multi_logloss: 1.4369\n",
      "[5]\ttrain's multi_logloss: 1.40831\tvalid's multi_logloss: 1.42474\n",
      "[6]\ttrain's multi_logloss: 1.39381\tvalid's multi_logloss: 1.41367\n",
      "[7]\ttrain's multi_logloss: 1.38357\tvalid's multi_logloss: 1.40652\n",
      "[8]\ttrain's multi_logloss: 1.37373\tvalid's multi_logloss: 1.40054\n",
      "[9]\ttrain's multi_logloss: 1.36794\tvalid's multi_logloss: 1.39795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.383802:  29%|###################1                                               | 2/7 [00:01<00:02,  1.81it/s]\u001b[32m[I 2021-03-23 23:24:22,407]\u001b[0m Trial 1 finished with value: 1.3917761261389772 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 1.3838018421928033.\u001b[0m\n",
      "feature_fraction, val_score: 1.383802:  29%|###################1                                               | 2/7 [00:01<00:02,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10]\ttrain's multi_logloss: 1.35889\tvalid's multi_logloss: 1.39178\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.35889\tvalid's multi_logloss: 1.39178\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.46455\tvalid's multi_logloss: 1.46696\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.44067\tvalid's multi_logloss: 1.44734\n",
      "[3]\ttrain's multi_logloss: 1.42059\tvalid's multi_logloss: 1.43131\n",
      "[4]\ttrain's multi_logloss: 1.40616\tvalid's multi_logloss: 1.42074\n",
      "[5]\ttrain's multi_logloss: 1.39136\tvalid's multi_logloss: 1.40972\n",
      "[6]\ttrain's multi_logloss: 1.37873\tvalid's multi_logloss: 1.40104\n",
      "[7]\ttrain's multi_logloss: 1.36845\tvalid's multi_logloss: 1.39443\n",
      "[8]\ttrain's multi_logloss: 1.35679\tvalid's multi_logloss: 1.38626\n",
      "[9]\ttrain's multi_logloss: 1.34771\tvalid's multi_logloss: 1.3805\n",
      "[10]\ttrain's multi_logloss: 1.34033\tvalid's multi_logloss: 1.37635\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.34033\tvalid's multi_logloss: 1.37635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.376345:  43%|############################7                                      | 3/7 [00:01<00:02,  1.73it/s]\u001b[32m[I 2021-03-23 23:24:23,010]\u001b[0m Trial 2 finished with value: 1.376345123871932 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 1.376345123871932.\u001b[0m\n",
      "feature_fraction, val_score: 1.376345:  43%|############################7                                      | 3/7 [00:01<00:02,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45999\tvalid's multi_logloss: 1.46234\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.4371\tvalid's multi_logloss: 1.44373\n",
      "[3]\ttrain's multi_logloss: 1.41541\tvalid's multi_logloss: 1.42622\n",
      "[4]\ttrain's multi_logloss: 1.4006\tvalid's multi_logloss: 1.41541\n",
      "[5]\ttrain's multi_logloss: 1.38663\tvalid's multi_logloss: 1.40553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.372837:  57%|######################################2                            | 4/7 [00:02<00:01,  1.68it/s]\u001b[32m[I 2021-03-23 23:24:23,639]\u001b[0m Trial 3 finished with value: 1.3728369252000108 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 1.3728369252000108.\u001b[0m\n",
      "feature_fraction, val_score: 1.372837:  57%|######################################2                            | 4/7 [00:02<00:01,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\ttrain's multi_logloss: 1.3731\tvalid's multi_logloss: 1.39608\n",
      "[7]\ttrain's multi_logloss: 1.36311\tvalid's multi_logloss: 1.38992\n",
      "[8]\ttrain's multi_logloss: 1.35251\tvalid's multi_logloss: 1.38252\n",
      "[9]\ttrain's multi_logloss: 1.34295\tvalid's multi_logloss: 1.37642\n",
      "[10]\ttrain's multi_logloss: 1.3357\tvalid's multi_logloss: 1.37284\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.3357\tvalid's multi_logloss: 1.37284\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45735\tvalid's multi_logloss: 1.45976\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.43206\tvalid's multi_logloss: 1.43907\n",
      "[3]\ttrain's multi_logloss: 1.41165\tvalid's multi_logloss: 1.42313\n",
      "[4]\ttrain's multi_logloss: 1.39437\tvalid's multi_logloss: 1.41018\n",
      "[5]\ttrain's multi_logloss: 1.38001\tvalid's multi_logloss: 1.3991\n",
      "[6]\ttrain's multi_logloss: 1.36772\tvalid's multi_logloss: 1.39081\n",
      "[7]\ttrain's multi_logloss: 1.35691\tvalid's multi_logloss: 1.38399\n",
      "[8]\ttrain's multi_logloss: 1.34721\tvalid's multi_logloss: 1.37769\n",
      "[9]\ttrain's multi_logloss: 1.33877\tvalid's multi_logloss: 1.37287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.368860:  71%|###############################################8                   | 5/7 [00:02<00:01,  1.60it/s]\u001b[32m[I 2021-03-23 23:24:24,310]\u001b[0m Trial 4 finished with value: 1.3688598626296546 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 1.3688598626296546.\u001b[0m\n",
      "feature_fraction, val_score: 1.368860:  71%|###############################################8                   | 5/7 [00:02<00:01,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.33119\tvalid's multi_logloss: 1.36886\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.33119\tvalid's multi_logloss: 1.36886\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45756\tvalid's multi_logloss: 1.46012\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.43268\tvalid's multi_logloss: 1.43973\n",
      "[3]\ttrain's multi_logloss: 1.41221\tvalid's multi_logloss: 1.42333\n",
      "[4]\ttrain's multi_logloss: 1.39726\tvalid's multi_logloss: 1.41269\n",
      "[5]\ttrain's multi_logloss: 1.38219\tvalid's multi_logloss: 1.40184\n",
      "[6]\ttrain's multi_logloss: 1.36925\tvalid's multi_logloss: 1.39326\n",
      "[7]\ttrain's multi_logloss: 1.35845\tvalid's multi_logloss: 1.38624\n",
      "[8]\ttrain's multi_logloss: 1.34832\tvalid's multi_logloss: 1.37966\n",
      "[9]\ttrain's multi_logloss: 1.3398\tvalid's multi_logloss: 1.37483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.368860:  86%|#########################################################4         | 6/7 [00:03<00:00,  1.61it/s]\u001b[32m[I 2021-03-23 23:24:24,930]\u001b[0m Trial 5 finished with value: 1.3704187162373622 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 1.3688598626296546.\u001b[0m\n",
      "feature_fraction, val_score: 1.368860:  86%|#########################################################4         | 6/7 [00:03<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.33227\tvalid's multi_logloss: 1.37042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.33227\tvalid's multi_logloss: 1.37042\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.46499\tvalid's multi_logloss: 1.46691\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.44147\tvalid's multi_logloss: 1.44789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "feature_fraction, val_score: 1.368860:  86%|#########################################################4         | 6/7 [00:04<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain's multi_logloss: 1.4247\tvalid's multi_logloss: 1.43527\n",
      "[4]\ttrain's multi_logloss: 1.40996\tvalid's multi_logloss: 1.4246\n",
      "[5]\ttrain's multi_logloss: 1.39481\tvalid's multi_logloss: 1.41294\n",
      "[6]\ttrain's multi_logloss: 1.38186\tvalid's multi_logloss: 1.40396\n",
      "[7]\ttrain's multi_logloss: 1.37179\tvalid's multi_logloss: 1.3975\n",
      "[8]\ttrain's multi_logloss: 1.3595\tvalid's multi_logloss: 1.38918\n",
      "[9]\ttrain's multi_logloss: 1.35211\tvalid's multi_logloss: 1.38535\n",
      "[10]\ttrain's multi_logloss: 1.34419\tvalid's multi_logloss: 1.38052\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.34419\tvalid's multi_logloss: 1.38052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.368860: 100%|###################################################################| 7/7 [00:04<00:00,  1.66it/s]\u001b[32m[I 2021-03-23 23:24:25,487]\u001b[0m Trial 6 finished with value: 1.3805196704700051 and parameters: {'feature_fraction': 0.6}. Best is trial 4 with value: 1.3688598626296546.\u001b[0m\n",
      "feature_fraction, val_score: 1.368860: 100%|###################################################################| 7/7 [00:04<00:00,  1.68it/s]\n",
      "num_leaves, val_score: 1.368860:   0%|                                                                                | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42683\tvalid's multi_logloss: 1.45889\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37378\tvalid's multi_logloss: 1.43778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32849\tvalid's multi_logloss: 1.4218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.28791\tvalid's multi_logloss: 1.40974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25293\tvalid's multi_logloss: 1.4004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.21875\tvalid's multi_logloss: 1.39204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.18774\tvalid's multi_logloss: 1.38621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.15992\tvalid's multi_logloss: 1.38041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.13389\tvalid's multi_logloss: 1.37611\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368860:   5%|###6                                                                    | 1/20 [00:01<00:26,  1.37s/it]\u001b[32m[I 2021-03-23 23:24:26,865]\u001b[0m Trial 7 finished with value: 1.372931882257032 and parameters: {'num_leaves': 1020}. Best is trial 7 with value: 1.372931882257032.\u001b[0m\n",
      "num_leaves, val_score: 1.368860:   5%|###6                                                                    | 1/20 [00:01<00:26,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42683\tvalid's multi_logloss: 1.45889\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37378\tvalid's multi_logloss: 1.43778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32849\tvalid's multi_logloss: 1.4218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.28791\tvalid's multi_logloss: 1.40974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25293\tvalid's multi_logloss: 1.4004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.21875\tvalid's multi_logloss: 1.39204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.18774\tvalid's multi_logloss: 1.38621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.15992\tvalid's multi_logloss: 1.38041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.13389\tvalid's multi_logloss: 1.37611\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368860:  10%|#######2                                                                | 2/20 [00:02<00:25,  1.44s/it]\u001b[32m[I 2021-03-23 23:24:28,363]\u001b[0m Trial 8 finished with value: 1.372931882257032 and parameters: {'num_leaves': 804}. Best is trial 7 with value: 1.372931882257032.\u001b[0m\n",
      "num_leaves, val_score: 1.368860:  10%|#######2                                                                | 2/20 [00:02<00:25,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.4492\tvalid's multi_logloss: 1.45936\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41672\tvalid's multi_logloss: 1.43796\n",
      "[3]\ttrain's multi_logloss: 1.38984\tvalid's multi_logloss: 1.4217\n",
      "[4]\ttrain's multi_logloss: 1.36667\tvalid's multi_logloss: 1.40832\n",
      "[5]\ttrain's multi_logloss: 1.34625\tvalid's multi_logloss: 1.3976\n",
      "[6]\ttrain's multi_logloss: 1.32836\tvalid's multi_logloss: 1.38926\n",
      "[7]\ttrain's multi_logloss: 1.31228\tvalid's multi_logloss: 1.3827\n",
      "[8]\ttrain's multi_logloss: 1.29768\tvalid's multi_logloss: 1.37654\n",
      "[9]\ttrain's multi_logloss: 1.28447\tvalid's multi_logloss: 1.37204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  15%|##########7                                                             | 3/20 [00:03<00:20,  1.18s/it]\u001b[32m[I 2021-03-23 23:24:29,218]\u001b[0m Trial 9 finished with value: 1.3680895920220333 and parameters: {'num_leaves': 76}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  15%|##########7                                                             | 3/20 [00:03<00:20,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27186\tvalid's multi_logloss: 1.36809\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27186\tvalid's multi_logloss: 1.36809\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42688\tvalid's multi_logloss: 1.45885\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37374\tvalid's multi_logloss: 1.43772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32845\tvalid's multi_logloss: 1.42178\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.28774\tvalid's multi_logloss: 1.40947\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25405\tvalid's multi_logloss: 1.40016\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.22012\tvalid's multi_logloss: 1.39144\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.18992\tvalid's multi_logloss: 1.38517\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.16255\tvalid's multi_logloss: 1.37949\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.13521\tvalid's multi_logloss: 1.37549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  20%|##############4                                                         | 4/20 [00:04<00:19,  1.19s/it]\u001b[32m[I 2021-03-23 23:24:30,425]\u001b[0m Trial 10 finished with value: 1.3722747175026555 and parameters: {'num_leaves': 347}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  20%|##############4                                                         | 4/20 [00:04<00:19,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.1115\tvalid's multi_logloss: 1.37227\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.1115\tvalid's multi_logloss: 1.37227\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42683\tvalid's multi_logloss: 1.45889\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37378\tvalid's multi_logloss: 1.43778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32849\tvalid's multi_logloss: 1.4218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.28791\tvalid's multi_logloss: 1.40974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25293\tvalid's multi_logloss: 1.4004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.21875\tvalid's multi_logloss: 1.39204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.18774\tvalid's multi_logloss: 1.38621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.15992\tvalid's multi_logloss: 1.38041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.13389\tvalid's multi_logloss: 1.37611\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  25%|##################                                                      | 5/20 [00:06<00:20,  1.36s/it]\u001b[32m[I 2021-03-23 23:24:32,084]\u001b[0m Trial 11 finished with value: 1.372931882257032 and parameters: {'num_leaves': 545}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  25%|##################                                                      | 5/20 [00:06<00:20,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.43798\tvalid's multi_logloss: 1.45875\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.39553\tvalid's multi_logloss: 1.43711\n",
      "[3]\ttrain's multi_logloss: 1.35953\tvalid's multi_logloss: 1.42081\n",
      "[4]\ttrain's multi_logloss: 1.32782\tvalid's multi_logloss: 1.40801\n",
      "[5]\ttrain's multi_logloss: 1.29965\tvalid's multi_logloss: 1.39783\n",
      "[6]\ttrain's multi_logloss: 1.27437\tvalid's multi_logloss: 1.38983\n",
      "[7]\ttrain's multi_logloss: 1.25053\tvalid's multi_logloss: 1.38327\n",
      "[8]\ttrain's multi_logloss: 1.22896\tvalid's multi_logloss: 1.37757\n",
      "[9]\ttrain's multi_logloss: 1.20853\tvalid's multi_logloss: 1.37338\n",
      "[10]\ttrain's multi_logloss: 1.19006\tvalid's multi_logloss: 1.36949\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.19006\tvalid's multi_logloss: 1.36949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  30%|#####################5                                                  | 6/20 [00:07<00:17,  1.26s/it]\u001b[32m[I 2021-03-23 23:24:33,160]\u001b[0m Trial 12 finished with value: 1.369494344206806 and parameters: {'num_leaves': 160}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  30%|#####################5                                                  | 6/20 [00:07<00:17,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.43047\tvalid's multi_logloss: 1.459\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.38088\tvalid's multi_logloss: 1.43744\n",
      "[3]\ttrain's multi_logloss: 1.33751\tvalid's multi_logloss: 1.42157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.30054\tvalid's multi_logloss: 1.4092\n",
      "[5]\ttrain's multi_logloss: 1.26698\tvalid's multi_logloss: 1.39874\n",
      "[6]\ttrain's multi_logloss: 1.23584\tvalid's multi_logloss: 1.39093\n",
      "[7]\ttrain's multi_logloss: 1.2073\tvalid's multi_logloss: 1.38467\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.18135\tvalid's multi_logloss: 1.37946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "num_leaves, val_score: 1.368090:  30%|#####################5                                                  | 6/20 [00:09<00:17,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.15677\tvalid's multi_logloss: 1.37575\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.1347\tvalid's multi_logloss: 1.37176\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.1347\tvalid's multi_logloss: 1.37176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  35%|#########################2                                              | 7/20 [00:09<00:16,  1.30s/it]\u001b[32m[I 2021-03-23 23:24:34,543]\u001b[0m Trial 13 finished with value: 1.3717557685100812 and parameters: {'num_leaves': 247}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  35%|#########################2                                              | 7/20 [00:09<00:16,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42683\tvalid's multi_logloss: 1.45889\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37378\tvalid's multi_logloss: 1.43778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32849\tvalid's multi_logloss: 1.4218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.28791\tvalid's multi_logloss: 1.40974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25293\tvalid's multi_logloss: 1.4004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.21875\tvalid's multi_logloss: 1.39204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.18774\tvalid's multi_logloss: 1.38621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.15992\tvalid's multi_logloss: 1.38041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.13389\tvalid's multi_logloss: 1.37611\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "num_leaves, val_score: 1.368090:  35%|#########################2                                              | 7/20 [00:10<00:16,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  40%|############################8                                           | 8/20 [00:10<00:17,  1.44s/it]\u001b[32m[I 2021-03-23 23:24:36,288]\u001b[0m Trial 14 finished with value: 1.372931882257032 and parameters: {'num_leaves': 984}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  40%|############################8                                           | 8/20 [00:10<00:17,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42683\tvalid's multi_logloss: 1.45889\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37378\tvalid's multi_logloss: 1.43778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32849\tvalid's multi_logloss: 1.4218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.28791\tvalid's multi_logloss: 1.40974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25293\tvalid's multi_logloss: 1.4004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.21875\tvalid's multi_logloss: 1.39204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.18774\tvalid's multi_logloss: 1.38621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.15992\tvalid's multi_logloss: 1.38041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.13389\tvalid's multi_logloss: 1.37611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "num_leaves, val_score: 1.368090:  40%|############################8                                           | 8/20 [00:12<00:17,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  45%|################################4                                       | 9/20 [00:12<00:16,  1.49s/it]\u001b[32m[I 2021-03-23 23:24:37,887]\u001b[0m Trial 15 finished with value: 1.372931882257032 and parameters: {'num_leaves': 548}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  45%|################################4                                       | 9/20 [00:12<00:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42683\tvalid's multi_logloss: 1.45889\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37378\tvalid's multi_logloss: 1.43778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32849\tvalid's multi_logloss: 1.4218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.28791\tvalid's multi_logloss: 1.40974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25293\tvalid's multi_logloss: 1.4004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.21875\tvalid's multi_logloss: 1.39204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.18774\tvalid's multi_logloss: 1.38621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.15992\tvalid's multi_logloss: 1.38041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.13389\tvalid's multi_logloss: 1.37611\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  50%|###################################5                                   | 10/20 [00:13<00:14,  1.50s/it]\u001b[32m[I 2021-03-23 23:24:39,385]\u001b[0m Trial 16 finished with value: 1.372931882257032 and parameters: {'num_leaves': 631}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  50%|###################################5                                   | 10/20 [00:13<00:14,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.4797\tvalid's multi_logloss: 1.47726\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.4719\tvalid's multi_logloss: 1.46958\n",
      "[3]\ttrain's multi_logloss: 1.46501\tvalid's multi_logloss: 1.46282\n",
      "[4]\ttrain's multi_logloss: 1.45907\tvalid's multi_logloss: 1.45684\n",
      "[5]\ttrain's multi_logloss: 1.45373\tvalid's multi_logloss: 1.45173\n",
      "[6]\ttrain's multi_logloss: 1.44892\tvalid's multi_logloss: 1.44685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  55%|#######################################                                | 11/20 [00:14<00:10,  1.17s/it]\u001b[32m[I 2021-03-23 23:24:39,842]\u001b[0m Trial 17 finished with value: 1.4323133692921335 and parameters: {'num_leaves': 2}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  55%|#######################################                                | 11/20 [00:14<00:10,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttrain's multi_logloss: 1.44476\tvalid's multi_logloss: 1.44272\n",
      "[8]\ttrain's multi_logloss: 1.4409\tvalid's multi_logloss: 1.43899\n",
      "[9]\ttrain's multi_logloss: 1.43729\tvalid's multi_logloss: 1.43538\n",
      "[10]\ttrain's multi_logloss: 1.4341\tvalid's multi_logloss: 1.43231\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.4341\tvalid's multi_logloss: 1.43231\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.46225\tvalid's multi_logloss: 1.46111\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.441\tvalid's multi_logloss: 1.44127\n",
      "[3]\ttrain's multi_logloss: 1.42404\tvalid's multi_logloss: 1.42574\n",
      "[4]\ttrain's multi_logloss: 1.41015\tvalid's multi_logloss: 1.41302\n",
      "[5]\ttrain's multi_logloss: 1.39886\tvalid's multi_logloss: 1.40291\n",
      "[6]\ttrain's multi_logloss: 1.38953\tvalid's multi_logloss: 1.39472\n",
      "[7]\ttrain's multi_logloss: 1.38164\tvalid's multi_logloss: 1.38795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  60%|##########################################6                            | 12/20 [00:15<00:08,  1.05s/it]\u001b[32m[I 2021-03-23 23:24:40,593]\u001b[0m Trial 18 finished with value: 1.3736976809749035 and parameters: {'num_leaves': 12}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  60%|##########################################6                            | 12/20 [00:15<00:08,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.37511\tvalid's multi_logloss: 1.38234\n",
      "[9]\ttrain's multi_logloss: 1.36932\tvalid's multi_logloss: 1.37772\n",
      "[10]\ttrain's multi_logloss: 1.36438\tvalid's multi_logloss: 1.3737\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.36438\tvalid's multi_logloss: 1.3737\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.43363\tvalid's multi_logloss: 1.45892\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.387\tvalid's multi_logloss: 1.43699\n",
      "[3]\ttrain's multi_logloss: 1.3471\tvalid's multi_logloss: 1.42068\n",
      "[4]\ttrain's multi_logloss: 1.31231\tvalid's multi_logloss: 1.40797\n",
      "[5]\ttrain's multi_logloss: 1.28023\tvalid's multi_logloss: 1.39783\n",
      "[6]\ttrain's multi_logloss: 1.2517\tvalid's multi_logloss: 1.38973\n",
      "[7]\ttrain's multi_logloss: 1.22533\tvalid's multi_logloss: 1.38296\n",
      "[8]\ttrain's multi_logloss: 1.20043\tvalid's multi_logloss: 1.37777\n",
      "[9]\ttrain's multi_logloss: 1.17752\tvalid's multi_logloss: 1.37319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  65%|##############################################1                        | 13/20 [00:16<00:07,  1.10s/it]\u001b[32m[I 2021-03-23 23:24:41,805]\u001b[0m Trial 19 finished with value: 1.3696480581047001 and parameters: {'num_leaves': 205}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  65%|##############################################1                        | 13/20 [00:16<00:07,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.15531\tvalid's multi_logloss: 1.36965\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.15531\tvalid's multi_logloss: 1.36965\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44606\tvalid's multi_logloss: 1.45914\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41076\tvalid's multi_logloss: 1.43787\n",
      "[3]\ttrain's multi_logloss: 1.38144\tvalid's multi_logloss: 1.42152\n",
      "[4]\ttrain's multi_logloss: 1.35601\tvalid's multi_logloss: 1.40797\n",
      "[5]\ttrain's multi_logloss: 1.33363\tvalid's multi_logloss: 1.39806\n",
      "[6]\ttrain's multi_logloss: 1.31352\tvalid's multi_logloss: 1.38925\n",
      "[7]\ttrain's multi_logloss: 1.29554\tvalid's multi_logloss: 1.38229\n",
      "[8]\ttrain's multi_logloss: 1.27881\tvalid's multi_logloss: 1.37683\n",
      "[9]\ttrain's multi_logloss: 1.26331\tvalid's multi_logloss: 1.37225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  70%|#################################################6                     | 14/20 [00:17<00:06,  1.04s/it]\u001b[32m[I 2021-03-23 23:24:42,703]\u001b[0m Trial 20 finished with value: 1.3683124882153472 and parameters: {'num_leaves': 97}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  70%|#################################################6                     | 14/20 [00:17<00:06,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.24848\tvalid's multi_logloss: 1.36831\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.24848\tvalid's multi_logloss: 1.36831\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44905\tvalid's multi_logloss: 1.45938\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41645\tvalid's multi_logloss: 1.43819\n",
      "[3]\ttrain's multi_logloss: 1.38961\tvalid's multi_logloss: 1.4216\n",
      "[4]\ttrain's multi_logloss: 1.36628\tvalid's multi_logloss: 1.40848\n",
      "[5]\ttrain's multi_logloss: 1.34586\tvalid's multi_logloss: 1.39779\n",
      "[6]\ttrain's multi_logloss: 1.32773\tvalid's multi_logloss: 1.38904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  75%|#####################################################2                 | 15/20 [00:17<00:04,  1.04it/s]\u001b[32m[I 2021-03-23 23:24:43,487]\u001b[0m Trial 21 finished with value: 1.3684108667745676 and parameters: {'num_leaves': 77}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  75%|#####################################################2                 | 15/20 [00:17<00:04,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttrain's multi_logloss: 1.31167\tvalid's multi_logloss: 1.38255\n",
      "[8]\ttrain's multi_logloss: 1.29695\tvalid's multi_logloss: 1.37688\n",
      "[9]\ttrain's multi_logloss: 1.28331\tvalid's multi_logloss: 1.37208\n",
      "[10]\ttrain's multi_logloss: 1.27113\tvalid's multi_logloss: 1.36841\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27113\tvalid's multi_logloss: 1.36841\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42741\tvalid's multi_logloss: 1.45885\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37488\tvalid's multi_logloss: 1.43769\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32958\tvalid's multi_logloss: 1.42172\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.289\tvalid's multi_logloss: 1.4094\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25544\tvalid's multi_logloss: 1.40015\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.22208\tvalid's multi_logloss: 1.39128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.1915\tvalid's multi_logloss: 1.3845\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.16388\tvalid's multi_logloss: 1.37898\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "num_leaves, val_score: 1.368090:  75%|#####################################################2                 | 15/20 [00:19<00:04,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.1386\tvalid's multi_logloss: 1.37528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.1158\tvalid's multi_logloss: 1.37194\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.1158\tvalid's multi_logloss: 1.37194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  80%|########################################################8              | 16/20 [00:19<00:04,  1.09s/it]\u001b[32m[I 2021-03-23 23:24:44,879]\u001b[0m Trial 22 finished with value: 1.3719368629086766 and parameters: {'num_leaves': 317}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  80%|########################################################8              | 16/20 [00:19<00:04,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42683\tvalid's multi_logloss: 1.45889\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37378\tvalid's multi_logloss: 1.43778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32849\tvalid's multi_logloss: 1.4218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.28791\tvalid's multi_logloss: 1.40974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25293\tvalid's multi_logloss: 1.4004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.21875\tvalid's multi_logloss: 1.39204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.18774\tvalid's multi_logloss: 1.38621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.15992\tvalid's multi_logloss: 1.38041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.13389\tvalid's multi_logloss: 1.37612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  85%|############################################################3          | 17/20 [00:20<00:03,  1.20s/it]\u001b[32m[I 2021-03-23 23:24:46,319]\u001b[0m Trial 23 finished with value: 1.3729321471386575 and parameters: {'num_leaves': 408}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  85%|############################################################3          | 17/20 [00:20<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44006\tvalid's multi_logloss: 1.4586\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.39926\tvalid's multi_logloss: 1.43692\n",
      "[3]\ttrain's multi_logloss: 1.36481\tvalid's multi_logloss: 1.42067\n",
      "[4]\ttrain's multi_logloss: 1.3348\tvalid's multi_logloss: 1.40798\n",
      "[5]\ttrain's multi_logloss: 1.30774\tvalid's multi_logloss: 1.39797\n",
      "[6]\ttrain's multi_logloss: 1.28384\tvalid's multi_logloss: 1.38959\n",
      "[7]\ttrain's multi_logloss: 1.26154\tvalid's multi_logloss: 1.38246\n",
      "[8]\ttrain's multi_logloss: 1.2406\tvalid's multi_logloss: 1.37674\n",
      "[9]\ttrain's multi_logloss: 1.22187\tvalid's multi_logloss: 1.37198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  90%|###############################################################9       | 18/20 [00:21<00:02,  1.17s/it]\u001b[32m[I 2021-03-23 23:24:47,448]\u001b[0m Trial 24 finished with value: 1.368090614574075 and parameters: {'num_leaves': 143}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  90%|###############################################################9       | 18/20 [00:21<00:02,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10]\ttrain's multi_logloss: 1.20399\tvalid's multi_logloss: 1.36809\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.20399\tvalid's multi_logloss: 1.36809\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.4613\tvalid's multi_logloss: 1.46075\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.43931\tvalid's multi_logloss: 1.4409\n",
      "[3]\ttrain's multi_logloss: 1.42197\tvalid's multi_logloss: 1.42526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090:  95%|###################################################################4   | 19/20 [00:22<00:00,  1.01it/s]\u001b[32m[I 2021-03-23 23:24:48,022]\u001b[0m Trial 25 finished with value: 1.3716711306291827 and parameters: {'num_leaves': 15}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090:  95%|###################################################################4   | 19/20 [00:22<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain's multi_logloss: 1.40738\tvalid's multi_logloss: 1.41233\n",
      "[5]\ttrain's multi_logloss: 1.39538\tvalid's multi_logloss: 1.40184\n",
      "[6]\ttrain's multi_logloss: 1.38558\tvalid's multi_logloss: 1.39359\n",
      "[7]\ttrain's multi_logloss: 1.37727\tvalid's multi_logloss: 1.38658\n",
      "[8]\ttrain's multi_logloss: 1.36987\tvalid's multi_logloss: 1.38063\n",
      "[9]\ttrain's multi_logloss: 1.36361\tvalid's multi_logloss: 1.37588\n",
      "[10]\ttrain's multi_logloss: 1.35815\tvalid's multi_logloss: 1.37167\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.35815\tvalid's multi_logloss: 1.37167\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's multi_logloss: 1.42683\tvalid's multi_logloss: 1.45889\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's multi_logloss: 1.37378\tvalid's multi_logloss: 1.43778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's multi_logloss: 1.32849\tvalid's multi_logloss: 1.4218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's multi_logloss: 1.28791\tvalid's multi_logloss: 1.40974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's multi_logloss: 1.25293\tvalid's multi_logloss: 1.4004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's multi_logloss: 1.21875\tvalid's multi_logloss: 1.39204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's multi_logloss: 1.18774\tvalid's multi_logloss: 1.38621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's multi_logloss: 1.15992\tvalid's multi_logloss: 1.38041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's multi_logloss: 1.13389\tvalid's multi_logloss: 1.37612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.10886\tvalid's multi_logloss: 1.37293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.368090: 100%|#######################################################################| 20/20 [00:23<00:00,  1.13s/it]\u001b[32m[I 2021-03-23 23:24:49,466]\u001b[0m Trial 26 finished with value: 1.3729324998070431 and parameters: {'num_leaves': 411}. Best is trial 9 with value: 1.3680895920220333.\u001b[0m\n",
      "num_leaves, val_score: 1.368090: 100%|#######################################################################| 20/20 [00:23<00:00,  1.20s/it]\n",
      "bagging, val_score: 1.368090:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45053\tvalid's multi_logloss: 1.46023\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41911\tvalid's multi_logloss: 1.44007\n",
      "[3]\ttrain's multi_logloss: 1.39244\tvalid's multi_logloss: 1.4237\n",
      "[4]\ttrain's multi_logloss: 1.37033\tvalid's multi_logloss: 1.41084\n",
      "[5]\ttrain's multi_logloss: 1.35109\tvalid's multi_logloss: 1.40111\n",
      "[6]\ttrain's multi_logloss: 1.33279\tvalid's multi_logloss: 1.39229\n",
      "[7]\ttrain's multi_logloss: 1.31648\tvalid's multi_logloss: 1.38476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.368090:  10%|#######5                                                                   | 1/10 [00:00<00:06,  1.32it/s]\u001b[32m[I 2021-03-23 23:24:50,232]\u001b[0m Trial 27 finished with value: 1.370393540887828 and parameters: {'bagging_fraction': 0.7152532376304014, 'bagging_freq': 5}. Best is trial 27 with value: 1.370393540887828.\u001b[0m\n",
      "bagging, val_score: 1.368090:  10%|#######5                                                                   | 1/10 [00:00<00:06,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.30184\tvalid's multi_logloss: 1.3788\n",
      "[9]\ttrain's multi_logloss: 1.28884\tvalid's multi_logloss: 1.37389\n",
      "[10]\ttrain's multi_logloss: 1.27668\tvalid's multi_logloss: 1.37039\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27668\tvalid's multi_logloss: 1.37039\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45101\tvalid's multi_logloss: 1.46195\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41975\tvalid's multi_logloss: 1.4421\n",
      "[3]\ttrain's multi_logloss: 1.39456\tvalid's multi_logloss: 1.42701\n",
      "[4]\ttrain's multi_logloss: 1.37338\tvalid's multi_logloss: 1.41523\n",
      "[5]\ttrain's multi_logloss: 1.35242\tvalid's multi_logloss: 1.4042\n",
      "[6]\ttrain's multi_logloss: 1.33413\tvalid's multi_logloss: 1.39514\n",
      "[7]\ttrain's multi_logloss: 1.31821\tvalid's multi_logloss: 1.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.368090:  20%|###############                                                            | 2/10 [00:01<00:05,  1.35it/s]\u001b[32m[I 2021-03-23 23:24:50,957]\u001b[0m Trial 28 finished with value: 1.3728917041814046 and parameters: {'bagging_fraction': 0.532465979348824, 'bagging_freq': 4}. Best is trial 27 with value: 1.370393540887828.\u001b[0m\n",
      "bagging, val_score: 1.368090:  20%|###############                                                            | 2/10 [00:01<00:05,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.30431\tvalid's multi_logloss: 1.38244\n",
      "[9]\ttrain's multi_logloss: 1.29073\tvalid's multi_logloss: 1.37694\n",
      "[10]\ttrain's multi_logloss: 1.27831\tvalid's multi_logloss: 1.37289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27831\tvalid's multi_logloss: 1.37289\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44963\tvalid's multi_logloss: 1.45986\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.4178\tvalid's multi_logloss: 1.43878\n",
      "[3]\ttrain's multi_logloss: 1.39127\tvalid's multi_logloss: 1.42241\n",
      "[4]\ttrain's multi_logloss: 1.36834\tvalid's multi_logloss: 1.40927\n",
      "[5]\ttrain's multi_logloss: 1.3486\tvalid's multi_logloss: 1.39888\n",
      "[6]\ttrain's multi_logloss: 1.33125\tvalid's multi_logloss: 1.39113\n",
      "[7]\ttrain's multi_logloss: 1.31467\tvalid's multi_logloss: 1.38387\n",
      "[8]\ttrain's multi_logloss: 1.30038\tvalid's multi_logloss: 1.3783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.368090:  30%|######################5                                                    | 3/10 [00:02<00:05,  1.23it/s]\u001b[32m[I 2021-03-23 23:24:51,854]\u001b[0m Trial 29 finished with value: 1.369651130172604 and parameters: {'bagging_fraction': 0.8844077679608086, 'bagging_freq': 6}. Best is trial 29 with value: 1.369651130172604.\u001b[0m\n",
      "bagging, val_score: 1.368090:  30%|######################5                                                    | 3/10 [00:02<00:05,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttrain's multi_logloss: 1.28692\tvalid's multi_logloss: 1.37348\n",
      "[10]\ttrain's multi_logloss: 1.27467\tvalid's multi_logloss: 1.36965\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27467\tvalid's multi_logloss: 1.36965\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45052\tvalid's multi_logloss: 1.46054\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41902\tvalid's multi_logloss: 1.44075\n",
      "[3]\ttrain's multi_logloss: 1.39349\tvalid's multi_logloss: 1.42602\n",
      "[4]\ttrain's multi_logloss: 1.37148\tvalid's multi_logloss: 1.41358\n",
      "[5]\ttrain's multi_logloss: 1.35238\tvalid's multi_logloss: 1.40411\n",
      "[6]\ttrain's multi_logloss: 1.33537\tvalid's multi_logloss: 1.39553\n",
      "[7]\ttrain's multi_logloss: 1.31822\tvalid's multi_logloss: 1.38749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.368090:  40%|##############################                                             | 4/10 [00:03<00:04,  1.26it/s]\u001b[32m[I 2021-03-23 23:24:52,632]\u001b[0m Trial 30 finished with value: 1.3730959159366753 and parameters: {'bagging_fraction': 0.6489591783194937, 'bagging_freq': 6}. Best is trial 29 with value: 1.369651130172604.\u001b[0m\n",
      "bagging, val_score: 1.368090:  40%|##############################                                             | 4/10 [00:03<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.30335\tvalid's multi_logloss: 1.38145\n",
      "[9]\ttrain's multi_logloss: 1.28987\tvalid's multi_logloss: 1.37666\n",
      "[10]\ttrain's multi_logloss: 1.27776\tvalid's multi_logloss: 1.3731\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27776\tvalid's multi_logloss: 1.3731\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45114\tvalid's multi_logloss: 1.46108\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41977\tvalid's multi_logloss: 1.44129\n",
      "[3]\ttrain's multi_logloss: 1.39294\tvalid's multi_logloss: 1.42451\n",
      "[4]\ttrain's multi_logloss: 1.36992\tvalid's multi_logloss: 1.41135\n",
      "[5]\ttrain's multi_logloss: 1.3494\tvalid's multi_logloss: 1.40045\n",
      "[6]\ttrain's multi_logloss: 1.33165\tvalid's multi_logloss: 1.39179\n",
      "[7]\ttrain's multi_logloss: 1.31538\tvalid's multi_logloss: 1.38479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.368090:  50%|#####################################5                                     | 5/10 [00:03<00:03,  1.28it/s]\u001b[32m[I 2021-03-23 23:24:53,385]\u001b[0m Trial 31 finished with value: 1.3702483709070943 and parameters: {'bagging_fraction': 0.6658820895811434, 'bagging_freq': 2}. Best is trial 29 with value: 1.369651130172604.\u001b[0m\n",
      "bagging, val_score: 1.368090:  50%|#####################################5                                     | 5/10 [00:03<00:03,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.30057\tvalid's multi_logloss: 1.37916\n",
      "[9]\ttrain's multi_logloss: 1.28683\tvalid's multi_logloss: 1.3742\n",
      "[10]\ttrain's multi_logloss: 1.27449\tvalid's multi_logloss: 1.37025\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27449\tvalid's multi_logloss: 1.37025\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45113\tvalid's multi_logloss: 1.46157\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.42103\tvalid's multi_logloss: 1.44224\n",
      "[3]\ttrain's multi_logloss: 1.39587\tvalid's multi_logloss: 1.4272\n",
      "[4]\ttrain's multi_logloss: 1.37419\tvalid's multi_logloss: 1.41546\n",
      "[5]\ttrain's multi_logloss: 1.35347\tvalid's multi_logloss: 1.40452\n",
      "[6]\ttrain's multi_logloss: 1.33552\tvalid's multi_logloss: 1.39606\n",
      "[7]\ttrain's multi_logloss: 1.31989\tvalid's multi_logloss: 1.38908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.368090:  60%|#############################################                              | 6/10 [00:04<00:03,  1.30it/s]\u001b[32m[I 2021-03-23 23:24:54,123]\u001b[0m Trial 32 finished with value: 1.3751706405585613 and parameters: {'bagging_fraction': 0.5019321219378374, 'bagging_freq': 4}. Best is trial 29 with value: 1.369651130172604.\u001b[0m\n",
      "bagging, val_score: 1.368090:  60%|#############################################                              | 6/10 [00:04<00:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.30602\tvalid's multi_logloss: 1.38358\n",
      "[9]\ttrain's multi_logloss: 1.29266\tvalid's multi_logloss: 1.37895\n",
      "[10]\ttrain's multi_logloss: 1.28056\tvalid's multi_logloss: 1.37517\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.28056\tvalid's multi_logloss: 1.37517\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44934\tvalid's multi_logloss: 1.45939\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41694\tvalid's multi_logloss: 1.43867\n",
      "[3]\ttrain's multi_logloss: 1.3902\tvalid's multi_logloss: 1.42158\n",
      "[4]\ttrain's multi_logloss: 1.36729\tvalid's multi_logloss: 1.40821\n",
      "[5]\ttrain's multi_logloss: 1.3472\tvalid's multi_logloss: 1.39774\n",
      "[6]\ttrain's multi_logloss: 1.32929\tvalid's multi_logloss: 1.38889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "bagging, val_score: 1.367673:  60%|#############################################                              | 6/10 [00:05<00:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttrain's multi_logloss: 1.31354\tvalid's multi_logloss: 1.38218\n",
      "[8]\ttrain's multi_logloss: 1.29875\tvalid's multi_logloss: 1.37636\n",
      "[9]\ttrain's multi_logloss: 1.28551\tvalid's multi_logloss: 1.37145\n",
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.367673:  70%|####################################################5                      | 7/10 [00:05<00:02,  1.25it/s]\u001b[32m[I 2021-03-23 23:24:54,990]\u001b[0m Trial 33 finished with value: 1.3676733013090394 and parameters: {'bagging_fraction': 0.9461463405162885, 'bagging_freq': 6}. Best is trial 33 with value: 1.3676733013090394.\u001b[0m\n",
      "bagging, val_score: 1.367673:  70%|####################################################5                      | 7/10 [00:05<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45027\tvalid's multi_logloss: 1.46073\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41911\tvalid's multi_logloss: 1.44025\n",
      "[3]\ttrain's multi_logloss: 1.39307\tvalid's multi_logloss: 1.42445\n",
      "[4]\ttrain's multi_logloss: 1.37065\tvalid's multi_logloss: 1.41174\n",
      "[5]\ttrain's multi_logloss: 1.3511\tvalid's multi_logloss: 1.40112\n",
      "[6]\ttrain's multi_logloss: 1.33403\tvalid's multi_logloss: 1.39263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.367673:  80%|############################################################               | 8/10 [00:06<00:01,  1.27it/s]\u001b[32m[I 2021-03-23 23:24:55,756]\u001b[0m Trial 34 finished with value: 1.3707313230987719 and parameters: {'bagging_fraction': 0.7698150521238648, 'bagging_freq': 6}. Best is trial 33 with value: 1.3676733013090394.\u001b[0m\n",
      "bagging, val_score: 1.367673:  80%|############################################################               | 8/10 [00:06<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttrain's multi_logloss: 1.31735\tvalid's multi_logloss: 1.38492\n",
      "[8]\ttrain's multi_logloss: 1.30278\tvalid's multi_logloss: 1.37907\n",
      "[9]\ttrain's multi_logloss: 1.2892\tvalid's multi_logloss: 1.37462\n",
      "[10]\ttrain's multi_logloss: 1.27731\tvalid's multi_logloss: 1.37073\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27731\tvalid's multi_logloss: 1.37073\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45136\tvalid's multi_logloss: 1.46148\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.42125\tvalid's multi_logloss: 1.44199\n",
      "[3]\ttrain's multi_logloss: 1.39618\tvalid's multi_logloss: 1.42694\n",
      "[4]\ttrain's multi_logloss: 1.37433\tvalid's multi_logloss: 1.41493\n",
      "[5]\ttrain's multi_logloss: 1.3559\tvalid's multi_logloss: 1.40558\n",
      "[6]\ttrain's multi_logloss: 1.33981\tvalid's multi_logloss: 1.3977\n",
      "[7]\ttrain's multi_logloss: 1.32343\tvalid's multi_logloss: 1.39091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.367673:  90%|###################################################################5       | 9/10 [00:07<00:00,  1.29it/s]\u001b[32m[I 2021-03-23 23:24:56,492]\u001b[0m Trial 35 finished with value: 1.3782711120720026 and parameters: {'bagging_fraction': 0.4649792345462929, 'bagging_freq': 6}. Best is trial 33 with value: 1.3676733013090394.\u001b[0m\n",
      "bagging, val_score: 1.367673:  90%|###################################################################5       | 9/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.30906\tvalid's multi_logloss: 1.38542\n",
      "[9]\ttrain's multi_logloss: 1.29626\tvalid's multi_logloss: 1.38149\n",
      "[10]\ttrain's multi_logloss: 1.28438\tvalid's multi_logloss: 1.37827\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.28438\tvalid's multi_logloss: 1.37827\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45122\tvalid's multi_logloss: 1.46102\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.42062\tvalid's multi_logloss: 1.44181\n",
      "[3]\ttrain's multi_logloss: 1.39556\tvalid's multi_logloss: 1.42646\n",
      "[4]\ttrain's multi_logloss: 1.37159\tvalid's multi_logloss: 1.41256\n",
      "[5]\ttrain's multi_logloss: 1.35181\tvalid's multi_logloss: 1.4022\n",
      "[6]\ttrain's multi_logloss: 1.33419\tvalid's multi_logloss: 1.39411\n",
      "[7]\ttrain's multi_logloss: 1.318\tvalid's multi_logloss: 1.38705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.367673: 100%|##########################################################################| 10/10 [00:07<00:00,  1.32it/s]\u001b[32m[I 2021-03-23 23:24:57,226]\u001b[0m Trial 36 finished with value: 1.3728117705225704 and parameters: {'bagging_fraction': 0.5226045303239479, 'bagging_freq': 3}. Best is trial 33 with value: 1.3676733013090394.\u001b[0m\n",
      "bagging, val_score: 1.367673: 100%|##########################################################################| 10/10 [00:07<00:00,  1.29it/s]\n",
      "feature_fraction_stage2, val_score: 1.367673:   0%|                                                                    | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.30373\tvalid's multi_logloss: 1.38173\n",
      "[9]\ttrain's multi_logloss: 1.29065\tvalid's multi_logloss: 1.37678\n",
      "[10]\ttrain's multi_logloss: 1.27804\tvalid's multi_logloss: 1.37281\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27804\tvalid's multi_logloss: 1.37281\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.4495\tvalid's multi_logloss: 1.45975\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41699\tvalid's multi_logloss: 1.439\n",
      "[3]\ttrain's multi_logloss: 1.39031\tvalid's multi_logloss: 1.42261\n",
      "[4]\ttrain's multi_logloss: 1.36737\tvalid's multi_logloss: 1.40914\n",
      "[5]\ttrain's multi_logloss: 1.34728\tvalid's multi_logloss: 1.39822\n",
      "[6]\ttrain's multi_logloss: 1.32962\tvalid's multi_logloss: 1.38967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 1.367673:  33%|####################                                        | 1/3 [00:00<00:01,  1.24it/s]\u001b[32m[I 2021-03-23 23:24:58,036]\u001b[0m Trial 37 finished with value: 1.3683028205972776 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 1.3683028205972776.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.367673:  33%|####################                                        | 1/3 [00:00<00:01,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttrain's multi_logloss: 1.31373\tvalid's multi_logloss: 1.38299\n",
      "[8]\ttrain's multi_logloss: 1.29914\tvalid's multi_logloss: 1.37738\n",
      "[9]\ttrain's multi_logloss: 1.28564\tvalid's multi_logloss: 1.37236\n",
      "[10]\ttrain's multi_logloss: 1.273\tvalid's multi_logloss: 1.3683\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.273\tvalid's multi_logloss: 1.3683\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44971\tvalid's multi_logloss: 1.45954\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41769\tvalid's multi_logloss: 1.4393\n",
      "[3]\ttrain's multi_logloss: 1.39052\tvalid's multi_logloss: 1.42241\n",
      "[4]\ttrain's multi_logloss: 1.36988\tvalid's multi_logloss: 1.41203\n",
      "[5]\ttrain's multi_logloss: 1.34937\tvalid's multi_logloss: 1.40102\n",
      "[6]\ttrain's multi_logloss: 1.3315\tvalid's multi_logloss: 1.39226\n",
      "[7]\ttrain's multi_logloss: 1.31467\tvalid's multi_logloss: 1.38491\n",
      "[8]\ttrain's multi_logloss: 1.29985\tvalid's multi_logloss: 1.37931\n",
      "[9]\ttrain's multi_logloss: 1.28611\tvalid's multi_logloss: 1.37419\n",
      "[10]\ttrain's multi_logloss: 1.27342\tvalid's multi_logloss: 1.36995\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27342\tvalid's multi_logloss: 1.36995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 1.367673:  67%|########################################                    | 2/3 [00:01<00:00,  1.22it/s]\u001b[32m[I 2021-03-23 23:24:58,866]\u001b[0m Trial 38 finished with value: 1.369950273019064 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 1.3683028205972776.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.367673:  67%|########################################                    | 2/3 [00:01<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44968\tvalid's multi_logloss: 1.45972\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41731\tvalid's multi_logloss: 1.43867\n",
      "[3]\ttrain's multi_logloss: 1.39068\tvalid's multi_logloss: 1.42165\n",
      "[4]\ttrain's multi_logloss: 1.36967\tvalid's multi_logloss: 1.41086\n",
      "[5]\ttrain's multi_logloss: 1.34942\tvalid's multi_logloss: 1.39979\n",
      "[6]\ttrain's multi_logloss: 1.33124\tvalid's multi_logloss: 1.39069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 1.367673: 100%|############################################################| 3/3 [00:02<00:00,  1.25it/s]\u001b[32m[I 2021-03-23 23:24:59,648]\u001b[0m Trial 39 finished with value: 1.3683566210363531 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 1.3683028205972776.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.367673: 100%|############################################################| 3/3 [00:02<00:00,  1.24it/s]\n",
      "  0%|                                                                                                                 | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttrain's multi_logloss: 1.31487\tvalid's multi_logloss: 1.38348\n",
      "[8]\ttrain's multi_logloss: 1.30022\tvalid's multi_logloss: 1.37721\n",
      "[9]\ttrain's multi_logloss: 1.28652\tvalid's multi_logloss: 1.37249\n",
      "[10]\ttrain's multi_logloss: 1.2742\tvalid's multi_logloss: 1.36836\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.2742\tvalid's multi_logloss: 1.36836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 1.367673:   0%|                                                                    | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44934\tvalid's multi_logloss: 1.45939\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41694\tvalid's multi_logloss: 1.43867\n",
      "[3]\ttrain's multi_logloss: 1.3902\tvalid's multi_logloss: 1.42158\n",
      "[4]\ttrain's multi_logloss: 1.36729\tvalid's multi_logloss: 1.40821\n",
      "[5]\ttrain's multi_logloss: 1.3472\tvalid's multi_logloss: 1.39774\n",
      "[6]\ttrain's multi_logloss: 1.32929\tvalid's multi_logloss: 1.38889\n",
      "[7]\ttrain's multi_logloss: 1.31354\tvalid's multi_logloss: 1.38218\n",
      "[8]\ttrain's multi_logloss: 1.29875\tvalid's multi_logloss: 1.37636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367673:   5%|###                                                         | 1/20 [00:00<00:18,  1.01it/s]\u001b[32m[I 2021-03-23 23:25:00,652]\u001b[0m Trial 40 finished with value: 1.3676733013426061 and parameters: {'lambda_l1': 3.4900842127182094e-07, 'lambda_l2': 7.860381557618969e-08}. Best is trial 40 with value: 1.3676733013426061.\u001b[0m\n",
      "regularization_factors, val_score: 1.367673:   5%|###                                                         | 1/20 [00:01<00:18,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttrain's multi_logloss: 1.28551\tvalid's multi_logloss: 1.37145\n",
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.4497\tvalid's multi_logloss: 1.45987\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41749\tvalid's multi_logloss: 1.43963\n",
      "[3]\ttrain's multi_logloss: 1.39069\tvalid's multi_logloss: 1.4228\n",
      "[4]\ttrain's multi_logloss: 1.36775\tvalid's multi_logloss: 1.40947\n",
      "[5]\ttrain's multi_logloss: 1.34763\tvalid's multi_logloss: 1.39814\n",
      "[6]\ttrain's multi_logloss: 1.33024\tvalid's multi_logloss: 1.3898\n",
      "[7]\ttrain's multi_logloss: 1.31424\tvalid's multi_logloss: 1.38292\n",
      "[8]\ttrain's multi_logloss: 1.29973\tvalid's multi_logloss: 1.37702\n",
      "[9]\ttrain's multi_logloss: 1.2863\tvalid's multi_logloss: 1.37206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367673:  10%|######                                                      | 2/20 [00:01<00:17,  1.05it/s]\u001b[32m[I 2021-03-23 23:25:01,570]\u001b[0m Trial 41 finished with value: 1.3678566933517833 and parameters: {'lambda_l1': 0.0506973649711401, 'lambda_l2': 0.012935858053310236}. Best is trial 40 with value: 1.3676733013426061.\u001b[0m\n",
      "regularization_factors, val_score: 1.367673:  10%|######                                                      | 2/20 [00:01<00:17,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27392\tvalid's multi_logloss: 1.36786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27392\tvalid's multi_logloss: 1.36786\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44934\tvalid's multi_logloss: 1.45939\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41694\tvalid's multi_logloss: 1.43867\n",
      "[3]\ttrain's multi_logloss: 1.3902\tvalid's multi_logloss: 1.42158\n",
      "[4]\ttrain's multi_logloss: 1.36729\tvalid's multi_logloss: 1.40821\n",
      "[5]\ttrain's multi_logloss: 1.3472\tvalid's multi_logloss: 1.39774\n",
      "[6]\ttrain's multi_logloss: 1.32929\tvalid's multi_logloss: 1.38889\n",
      "[7]\ttrain's multi_logloss: 1.31354\tvalid's multi_logloss: 1.38218\n",
      "[8]\ttrain's multi_logloss: 1.29875\tvalid's multi_logloss: 1.37636\n",
      "[9]\ttrain's multi_logloss: 1.28551\tvalid's multi_logloss: 1.37145\n",
      "[10]\ttrain's multi_logloss: 1.27276\tvalid's multi_logloss: 1.36771\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27276\tvalid's multi_logloss: 1.36771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367673:  15%|#########                                                   | 3/20 [00:02<00:15,  1.08it/s]\u001b[32m[I 2021-03-23 23:25:02,467]\u001b[0m Trial 42 finished with value: 1.3677062062597733 and parameters: {'lambda_l1': 1.8617372053529127e-08, 'lambda_l2': 0.00012586192027249239}. Best is trial 40 with value: 1.3676733013426061.\u001b[0m\n",
      "regularization_factors, val_score: 1.367673:  15%|#########                                                   | 3/20 [00:02<00:15,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44983\tvalid's multi_logloss: 1.45969\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41744\tvalid's multi_logloss: 1.43914\n",
      "[3]\ttrain's multi_logloss: 1.39076\tvalid's multi_logloss: 1.42234\n",
      "[4]\ttrain's multi_logloss: 1.36804\tvalid's multi_logloss: 1.40948\n",
      "[5]\ttrain's multi_logloss: 1.34805\tvalid's multi_logloss: 1.39903\n",
      "[6]\ttrain's multi_logloss: 1.3305\tvalid's multi_logloss: 1.39049\n",
      "[7]\ttrain's multi_logloss: 1.31446\tvalid's multi_logloss: 1.38344\n",
      "[8]\ttrain's multi_logloss: 1.30036\tvalid's multi_logloss: 1.37761\n",
      "[9]\ttrain's multi_logloss: 1.28659\tvalid's multi_logloss: 1.37197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367673:  20%|############                                                | 4/20 [00:03<00:14,  1.09it/s]\u001b[32m[I 2021-03-23 23:25:03,367]\u001b[0m Trial 43 finished with value: 1.3682065772691159 and parameters: {'lambda_l1': 0.00756157351117483, 'lambda_l2': 0.09369925298204822}. Best is trial 40 with value: 1.3676733013426061.\u001b[0m\n",
      "regularization_factors, val_score: 1.367673:  20%|############                                                | 4/20 [00:03<00:14,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27427\tvalid's multi_logloss: 1.36821\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27427\tvalid's multi_logloss: 1.36821\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44934\tvalid's multi_logloss: 1.45939\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41694\tvalid's multi_logloss: 1.43867\n",
      "[3]\ttrain's multi_logloss: 1.3902\tvalid's multi_logloss: 1.42158\n",
      "[4]\ttrain's multi_logloss: 1.36729\tvalid's multi_logloss: 1.40821\n",
      "[5]\ttrain's multi_logloss: 1.3472\tvalid's multi_logloss: 1.39774\n",
      "[6]\ttrain's multi_logloss: 1.32929\tvalid's multi_logloss: 1.38889\n",
      "[7]\ttrain's multi_logloss: 1.31354\tvalid's multi_logloss: 1.38218\n",
      "[8]\ttrain's multi_logloss: 1.29875\tvalid's multi_logloss: 1.37636\n",
      "[9]\ttrain's multi_logloss: 1.28551\tvalid's multi_logloss: 1.37145\n",
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367673:  25%|###############                                             | 5/20 [00:04<00:13,  1.10it/s]\u001b[32m[I 2021-03-23 23:25:04,254]\u001b[0m Trial 44 finished with value: 1.3676733012868916 and parameters: {'lambda_l1': 5.2898293159590377e-08, 'lambda_l2': 1.0469618642509254e-07}. Best is trial 44 with value: 1.3676733012868916.\u001b[0m\n",
      "regularization_factors, val_score: 1.367673:  25%|###############                                             | 5/20 [00:04<00:13,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44934\tvalid's multi_logloss: 1.45936\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41694\tvalid's multi_logloss: 1.43864\n",
      "[3]\ttrain's multi_logloss: 1.39021\tvalid's multi_logloss: 1.42155\n",
      "[4]\ttrain's multi_logloss: 1.36727\tvalid's multi_logloss: 1.4082\n",
      "[5]\ttrain's multi_logloss: 1.34718\tvalid's multi_logloss: 1.39765\n",
      "[6]\ttrain's multi_logloss: 1.32925\tvalid's multi_logloss: 1.38869\n",
      "[7]\ttrain's multi_logloss: 1.31346\tvalid's multi_logloss: 1.38202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367479:  30%|##################                                          | 6/20 [00:05<00:12,  1.08it/s]\u001b[32m[I 2021-03-23 23:25:05,214]\u001b[0m Trial 45 finished with value: 1.3674794722894883 and parameters: {'lambda_l1': 0.0010697109232904929, 'lambda_l2': 8.459376882139949e-07}. Best is trial 45 with value: 1.3674794722894883.\u001b[0m\n",
      "regularization_factors, val_score: 1.367479:  30%|##################                                          | 6/20 [00:05<00:12,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.29878\tvalid's multi_logloss: 1.37607\n",
      "[9]\ttrain's multi_logloss: 1.2855\tvalid's multi_logloss: 1.37142\n",
      "[10]\ttrain's multi_logloss: 1.27271\tvalid's multi_logloss: 1.36748\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27271\tvalid's multi_logloss: 1.36748\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45135\tvalid's multi_logloss: 1.46027\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.42035\tvalid's multi_logloss: 1.43949\n",
      "[3]\ttrain's multi_logloss: 1.39409\tvalid's multi_logloss: 1.42248\n",
      "[4]\ttrain's multi_logloss: 1.3716\tvalid's multi_logloss: 1.40932\n",
      "[5]\ttrain's multi_logloss: 1.35245\tvalid's multi_logloss: 1.39885\n",
      "[6]\ttrain's multi_logloss: 1.33512\tvalid's multi_logloss: 1.39001\n",
      "[7]\ttrain's multi_logloss: 1.31972\tvalid's multi_logloss: 1.38343\n",
      "[8]\ttrain's multi_logloss: 1.3056\tvalid's multi_logloss: 1.37764\n",
      "[9]\ttrain's multi_logloss: 1.29257\tvalid's multi_logloss: 1.37223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367479:  35%|#####################                                       | 7/20 [00:07<00:14,  1.13s/it]\u001b[32m[I 2021-03-23 23:25:06,757]\u001b[0m Trial 46 finished with value: 1.3680698938982148 and parameters: {'lambda_l1': 0.00011042951384541278, 'lambda_l2': 1.0263971071416762}. Best is trial 45 with value: 1.3674794722894883.\u001b[0m\n",
      "regularization_factors, val_score: 1.367479:  35%|#####################                                       | 7/20 [00:07<00:14,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.28053\tvalid's multi_logloss: 1.36807\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.28053\tvalid's multi_logloss: 1.36807\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44964\tvalid's multi_logloss: 1.45981\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.4171\tvalid's multi_logloss: 1.43909\n",
      "[3]\ttrain's multi_logloss: 1.39031\tvalid's multi_logloss: 1.42216\n",
      "[4]\ttrain's multi_logloss: 1.36753\tvalid's multi_logloss: 1.40912\n",
      "[5]\ttrain's multi_logloss: 1.34737\tvalid's multi_logloss: 1.39805\n",
      "[6]\ttrain's multi_logloss: 1.32983\tvalid's multi_logloss: 1.38907\n",
      "[7]\ttrain's multi_logloss: 1.31375\tvalid's multi_logloss: 1.38226\n",
      "[8]\ttrain's multi_logloss: 1.29962\tvalid's multi_logloss: 1.37659\n",
      "[9]\ttrain's multi_logloss: 1.28588\tvalid's multi_logloss: 1.37159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367449:  40%|########################                                    | 8/20 [00:08<00:13,  1.14s/it]\u001b[32m[I 2021-03-23 23:25:07,937]\u001b[0m Trial 47 finished with value: 1.3674491518956335 and parameters: {'lambda_l1': 4.0138803309537324e-07, 'lambda_l2': 0.015106971093803528}. Best is trial 47 with value: 1.3674491518956335.\u001b[0m\n",
      "regularization_factors, val_score: 1.367449:  40%|########################                                    | 8/20 [00:08<00:13,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27309\tvalid's multi_logloss: 1.36745\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27309\tvalid's multi_logloss: 1.36745\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44968\tvalid's multi_logloss: 1.45978\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41748\tvalid's multi_logloss: 1.43957\n",
      "[3]\ttrain's multi_logloss: 1.39067\tvalid's multi_logloss: 1.42268\n",
      "[4]\ttrain's multi_logloss: 1.3677\tvalid's multi_logloss: 1.4095\n",
      "[5]\ttrain's multi_logloss: 1.34762\tvalid's multi_logloss: 1.39868\n",
      "[6]\ttrain's multi_logloss: 1.33021\tvalid's multi_logloss: 1.39034\n",
      "[7]\ttrain's multi_logloss: 1.31409\tvalid's multi_logloss: 1.38318\n",
      "[8]\ttrain's multi_logloss: 1.29982\tvalid's multi_logloss: 1.37712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367449:  45%|###########################                                 | 9/20 [00:09<00:11,  1.09s/it]\u001b[32m[I 2021-03-23 23:25:08,897]\u001b[0m Trial 48 finished with value: 1.3677484225559606 and parameters: {'lambda_l1': 0.08032782717769295, 'lambda_l2': 3.031399576973134e-06}. Best is trial 47 with value: 1.3674491518956335.\u001b[0m\n",
      "regularization_factors, val_score: 1.367449:  45%|###########################                                 | 9/20 [00:09<00:11,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttrain's multi_logloss: 1.28638\tvalid's multi_logloss: 1.37196\n",
      "[10]\ttrain's multi_logloss: 1.27351\tvalid's multi_logloss: 1.36775\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27351\tvalid's multi_logloss: 1.36775\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45008\tvalid's multi_logloss: 1.45982\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41792\tvalid's multi_logloss: 1.43938\n",
      "[3]\ttrain's multi_logloss: 1.39143\tvalid's multi_logloss: 1.42321\n",
      "[4]\ttrain's multi_logloss: 1.36877\tvalid's multi_logloss: 1.41039\n",
      "[5]\ttrain's multi_logloss: 1.34883\tvalid's multi_logloss: 1.39957\n",
      "[6]\ttrain's multi_logloss: 1.33104\tvalid's multi_logloss: 1.39108\n",
      "[7]\ttrain's multi_logloss: 1.3151\tvalid's multi_logloss: 1.3841\n",
      "[8]\ttrain's multi_logloss: 1.30081\tvalid's multi_logloss: 1.37833\n",
      "[9]\ttrain's multi_logloss: 1.28702\tvalid's multi_logloss: 1.37327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367449:  50%|#############################5                             | 10/20 [00:10<00:10,  1.03s/it]\u001b[32m[I 2021-03-23 23:25:09,802]\u001b[0m Trial 49 finished with value: 1.3692965436301936 and parameters: {'lambda_l1': 0.3026420773550114, 'lambda_l2': 1.5261086869876538e-07}. Best is trial 47 with value: 1.3674491518956335.\u001b[0m\n",
      "regularization_factors, val_score: 1.367449:  50%|#############################5                             | 10/20 [00:10<00:10,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27465\tvalid's multi_logloss: 1.3693\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27465\tvalid's multi_logloss: 1.3693\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45569\tvalid's multi_logloss: 1.46129\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.42817\tvalid's multi_logloss: 1.4414\n",
      "[3]\ttrain's multi_logloss: 1.40425\tvalid's multi_logloss: 1.42443\n",
      "[4]\ttrain's multi_logloss: 1.38401\tvalid's multi_logloss: 1.41126\n",
      "[5]\ttrain's multi_logloss: 1.36643\tvalid's multi_logloss: 1.40065\n",
      "[6]\ttrain's multi_logloss: 1.35062\tvalid's multi_logloss: 1.39161\n",
      "[7]\ttrain's multi_logloss: 1.33665\tvalid's multi_logloss: 1.38473\n",
      "[8]\ttrain's multi_logloss: 1.32397\tvalid's multi_logloss: 1.37854\n",
      "[9]\ttrain's multi_logloss: 1.31211\tvalid's multi_logloss: 1.37305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367449:  55%|################################4                          | 11/20 [00:11<00:09,  1.00s/it]\u001b[32m[I 2021-03-23 23:25:10,742]\u001b[0m Trial 50 finished with value: 1.3687732997307307 and parameters: {'lambda_l1': 1.203465648526331e-05, 'lambda_l2': 8.841097826026198}. Best is trial 47 with value: 1.3674491518956335.\u001b[0m\n",
      "regularization_factors, val_score: 1.367449:  55%|################################4                          | 11/20 [00:11<00:09,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.30165\tvalid's multi_logloss: 1.36877\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.30165\tvalid's multi_logloss: 1.36877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45752\tvalid's multi_logloss: 1.46133\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.43185\tvalid's multi_logloss: 1.44137\n",
      "[3]\ttrain's multi_logloss: 1.41051\tvalid's multi_logloss: 1.4251\n",
      "[4]\ttrain's multi_logloss: 1.39229\tvalid's multi_logloss: 1.41187\n",
      "[5]\ttrain's multi_logloss: 1.37645\tvalid's multi_logloss: 1.40124\n",
      "[6]\ttrain's multi_logloss: 1.36274\tvalid's multi_logloss: 1.39247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367449:  60%|###################################4                       | 12/20 [00:11<00:07,  1.06it/s]\u001b[32m[I 2021-03-23 23:25:11,567]\u001b[0m Trial 51 finished with value: 1.37003636575344 and parameters: {'lambda_l1': 8.40164514912026, 'lambda_l2': 0.0004259371169319602}. Best is trial 47 with value: 1.3674491518956335.\u001b[0m\n",
      "regularization_factors, val_score: 1.367449:  60%|###################################4                       | 12/20 [00:11<00:07,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttrain's multi_logloss: 1.35027\tvalid's multi_logloss: 1.38525\n",
      "[8]\ttrain's multi_logloss: 1.33956\tvalid's multi_logloss: 1.3793\n",
      "[9]\ttrain's multi_logloss: 1.32965\tvalid's multi_logloss: 1.37444\n",
      "[10]\ttrain's multi_logloss: 1.3205\tvalid's multi_logloss: 1.37004\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.3205\tvalid's multi_logloss: 1.37004\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44934\tvalid's multi_logloss: 1.45939\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41694\tvalid's multi_logloss: 1.43867\n",
      "[3]\ttrain's multi_logloss: 1.3902\tvalid's multi_logloss: 1.42158\n",
      "[4]\ttrain's multi_logloss: 1.36729\tvalid's multi_logloss: 1.40821\n",
      "[5]\ttrain's multi_logloss: 1.3472\tvalid's multi_logloss: 1.39774\n",
      "[6]\ttrain's multi_logloss: 1.32929\tvalid's multi_logloss: 1.38889\n",
      "[7]\ttrain's multi_logloss: 1.31354\tvalid's multi_logloss: 1.38218\n",
      "[8]\ttrain's multi_logloss: 1.29875\tvalid's multi_logloss: 1.37636\n",
      "[9]\ttrain's multi_logloss: 1.28552\tvalid's multi_logloss: 1.37145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367449:  65%|######################################3                    | 13/20 [00:12<00:06,  1.07it/s]\u001b[32m[I 2021-03-23 23:25:12,483]\u001b[0m Trial 52 finished with value: 1.3677061939355237 and parameters: {'lambda_l1': 3.371667207244023e-06, 'lambda_l2': 0.00016836947292476033}. Best is trial 47 with value: 1.3674491518956335.\u001b[0m\n",
      "regularization_factors, val_score: 1.367449:  65%|######################################3                    | 13/20 [00:12<00:06,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27276\tvalid's multi_logloss: 1.36771\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27276\tvalid's multi_logloss: 1.36771\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.4496\tvalid's multi_logloss: 1.45975\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41696\tvalid's multi_logloss: 1.4388\n",
      "[3]\ttrain's multi_logloss: 1.39022\tvalid's multi_logloss: 1.42178\n",
      "[4]\ttrain's multi_logloss: 1.36728\tvalid's multi_logloss: 1.40851\n",
      "[5]\ttrain's multi_logloss: 1.3473\tvalid's multi_logloss: 1.3982\n",
      "[6]\ttrain's multi_logloss: 1.32976\tvalid's multi_logloss: 1.38915\n",
      "[7]\ttrain's multi_logloss: 1.31394\tvalid's multi_logloss: 1.38265\n",
      "[8]\ttrain's multi_logloss: 1.29944\tvalid's multi_logloss: 1.3769\n",
      "[9]\ttrain's multi_logloss: 1.28586\tvalid's multi_logloss: 1.37194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367269:  70%|#########################################3                 | 14/20 [00:13<00:05,  1.07it/s]\u001b[32m[I 2021-03-23 23:25:13,392]\u001b[0m Trial 53 finished with value: 1.367269119996364 and parameters: {'lambda_l1': 0.001566887018799462, 'lambda_l2': 1.1688701929536941e-05}. Best is trial 53 with value: 1.367269119996364.\u001b[0m\n",
      "regularization_factors, val_score: 1.367269:  70%|#########################################3                 | 14/20 [00:13<00:05,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27287\tvalid's multi_logloss: 1.36727\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27287\tvalid's multi_logloss: 1.36727\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44964\tvalid's multi_logloss: 1.45981\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.4171\tvalid's multi_logloss: 1.43909\n",
      "[3]\ttrain's multi_logloss: 1.39031\tvalid's multi_logloss: 1.42216\n",
      "[4]\ttrain's multi_logloss: 1.36753\tvalid's multi_logloss: 1.40912\n",
      "[5]\ttrain's multi_logloss: 1.34738\tvalid's multi_logloss: 1.39805\n",
      "[6]\ttrain's multi_logloss: 1.32983\tvalid's multi_logloss: 1.38907\n",
      "[7]\ttrain's multi_logloss: 1.31375\tvalid's multi_logloss: 1.38226\n",
      "[8]\ttrain's multi_logloss: 1.29962\tvalid's multi_logloss: 1.37659\n",
      "[9]\ttrain's multi_logloss: 1.28589\tvalid's multi_logloss: 1.37159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367269:  75%|############################################2              | 15/20 [00:14<00:04,  1.08it/s]\u001b[32m[I 2021-03-23 23:25:14,303]\u001b[0m Trial 54 finished with value: 1.3674222746120304 and parameters: {'lambda_l1': 0.0001641280544437046, 'lambda_l2': 0.01574953894040649}. Best is trial 53 with value: 1.367269119996364.\u001b[0m\n",
      "regularization_factors, val_score: 1.367269:  75%|############################################2              | 15/20 [00:14<00:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27311\tvalid's multi_logloss: 1.36742\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27311\tvalid's multi_logloss: 1.36742\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44934\tvalid's multi_logloss: 1.45939\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41694\tvalid's multi_logloss: 1.43867\n",
      "[3]\ttrain's multi_logloss: 1.3902\tvalid's multi_logloss: 1.42158\n",
      "[4]\ttrain's multi_logloss: 1.36729\tvalid's multi_logloss: 1.40821\n",
      "[5]\ttrain's multi_logloss: 1.3472\tvalid's multi_logloss: 1.39774\n",
      "[6]\ttrain's multi_logloss: 1.32929\tvalid's multi_logloss: 1.38889\n",
      "[7]\ttrain's multi_logloss: 1.31354\tvalid's multi_logloss: 1.38218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367269:  80%|###############################################2           | 16/20 [00:15<00:03,  1.07it/s]\u001b[32m[I 2021-03-23 23:25:15,246]\u001b[0m Trial 55 finished with value: 1.3676733666487608 and parameters: {'lambda_l1': 0.00041790120141711084, 'lambda_l2': 6.2475659325068745e-06}. Best is trial 53 with value: 1.367269119996364.\u001b[0m\n",
      "regularization_factors, val_score: 1.367269:  80%|###############################################2           | 16/20 [00:15<00:03,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.29875\tvalid's multi_logloss: 1.37636\n",
      "[9]\ttrain's multi_logloss: 1.28552\tvalid's multi_logloss: 1.37145\n",
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44935\tvalid's multi_logloss: 1.45936\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41695\tvalid's multi_logloss: 1.4386\n",
      "[3]\ttrain's multi_logloss: 1.39022\tvalid's multi_logloss: 1.42153\n",
      "[4]\ttrain's multi_logloss: 1.36728\tvalid's multi_logloss: 1.40816\n",
      "[5]\ttrain's multi_logloss: 1.34716\tvalid's multi_logloss: 1.39774\n",
      "[6]\ttrain's multi_logloss: 1.32937\tvalid's multi_logloss: 1.3891\n",
      "[7]\ttrain's multi_logloss: 1.3135\tvalid's multi_logloss: 1.38241\n",
      "[8]\ttrain's multi_logloss: 1.29917\tvalid's multi_logloss: 1.37661\n",
      "[9]\ttrain's multi_logloss: 1.28551\tvalid's multi_logloss: 1.37177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367269:  85%|##################################################1        | 17/20 [00:16<00:02,  1.04it/s]\u001b[32m[I 2021-03-23 23:25:16,288]\u001b[0m Trial 56 finished with value: 1.3673699398791526 and parameters: {'lambda_l1': 3.233233733341727e-05, 'lambda_l2': 0.0031172063897863408}. Best is trial 53 with value: 1.367269119996364.\u001b[0m\n",
      "regularization_factors, val_score: 1.367269:  85%|##################################################1        | 17/20 [00:16<00:02,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27292\tvalid's multi_logloss: 1.36737\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27292\tvalid's multi_logloss: 1.36737\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44934\tvalid's multi_logloss: 1.45939\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41694\tvalid's multi_logloss: 1.43867\n",
      "[3]\ttrain's multi_logloss: 1.3902\tvalid's multi_logloss: 1.42158\n",
      "[4]\ttrain's multi_logloss: 1.36729\tvalid's multi_logloss: 1.40821\n",
      "[5]\ttrain's multi_logloss: 1.3472\tvalid's multi_logloss: 1.39774\n",
      "[6]\ttrain's multi_logloss: 1.32929\tvalid's multi_logloss: 1.38889\n",
      "[7]\ttrain's multi_logloss: 1.31354\tvalid's multi_logloss: 1.38218\n",
      "[8]\ttrain's multi_logloss: 1.29875\tvalid's multi_logloss: 1.37636\n",
      "[9]\ttrain's multi_logloss: 1.28551\tvalid's multi_logloss: 1.37145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367269:  90%|#####################################################1     | 18/20 [00:17<00:01,  1.05it/s]\u001b[32m[I 2021-03-23 23:25:17,207]\u001b[0m Trial 57 finished with value: 1.3676732968525478 and parameters: {'lambda_l1': 1.3748091765544791e-05, 'lambda_l2': 2.2485978374388747e-05}. Best is trial 53 with value: 1.367269119996364.\u001b[0m\n",
      "regularization_factors, val_score: 1.367269:  90%|#####################################################1     | 18/20 [00:17<00:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27274\tvalid's multi_logloss: 1.36767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44961\tvalid's multi_logloss: 1.45975\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41698\tvalid's multi_logloss: 1.43881\n",
      "[3]\ttrain's multi_logloss: 1.39024\tvalid's multi_logloss: 1.42179\n",
      "[4]\ttrain's multi_logloss: 1.36735\tvalid's multi_logloss: 1.40851\n",
      "[5]\ttrain's multi_logloss: 1.34734\tvalid's multi_logloss: 1.39787\n",
      "[6]\ttrain's multi_logloss: 1.32968\tvalid's multi_logloss: 1.38909\n",
      "[7]\ttrain's multi_logloss: 1.31372\tvalid's multi_logloss: 1.38259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367269:  95%|########################################################   | 19/20 [00:18<00:00,  1.03it/s]\u001b[32m[I 2021-03-23 23:25:18,229]\u001b[0m Trial 58 finished with value: 1.3674765847877115 and parameters: {'lambda_l1': 0.007043392498995603, 'lambda_l2': 0.0010236555151826423}. Best is trial 53 with value: 1.367269119996364.\u001b[0m\n",
      "regularization_factors, val_score: 1.367269:  95%|########################################################   | 19/20 [00:18<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain's multi_logloss: 1.29939\tvalid's multi_logloss: 1.37721\n",
      "[9]\ttrain's multi_logloss: 1.28556\tvalid's multi_logloss: 1.37175\n",
      "[10]\ttrain's multi_logloss: 1.2729\tvalid's multi_logloss: 1.36748\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.2729\tvalid's multi_logloss: 1.36748\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45208\tvalid's multi_logloss: 1.46044\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.4221\tvalid's multi_logloss: 1.44014\n",
      "[3]\ttrain's multi_logloss: 1.39667\tvalid's multi_logloss: 1.42352\n",
      "[4]\ttrain's multi_logloss: 1.37493\tvalid's multi_logloss: 1.41034\n",
      "[5]\ttrain's multi_logloss: 1.35634\tvalid's multi_logloss: 1.3998\n",
      "[6]\ttrain's multi_logloss: 1.33993\tvalid's multi_logloss: 1.39105\n",
      "[7]\ttrain's multi_logloss: 1.32501\tvalid's multi_logloss: 1.38351\n",
      "[8]\ttrain's multi_logloss: 1.31166\tvalid's multi_logloss: 1.37788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.367269: 100%|###########################################################| 20/20 [00:19<00:00,  1.07it/s]\u001b[32m[I 2021-03-23 23:25:19,086]\u001b[0m Trial 59 finished with value: 1.3685019858809009 and parameters: {'lambda_l1': 2.1489752094696875, 'lambda_l2': 0.0034972676824331895}. Best is trial 53 with value: 1.367269119996364.\u001b[0m\n",
      "regularization_factors, val_score: 1.367269: 100%|###########################################################| 20/20 [00:19<00:00,  1.03it/s]\n",
      "min_data_in_leaf, val_score: 1.367269:   0%|                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttrain's multi_logloss: 1.29897\tvalid's multi_logloss: 1.37302\n",
      "[10]\ttrain's multi_logloss: 1.28734\tvalid's multi_logloss: 1.3685\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.28734\tvalid's multi_logloss: 1.3685\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.4506\tvalid's multi_logloss: 1.4596\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41919\tvalid's multi_logloss: 1.43838\n",
      "[3]\ttrain's multi_logloss: 1.39319\tvalid's multi_logloss: 1.42108\n",
      "[4]\ttrain's multi_logloss: 1.37057\tvalid's multi_logloss: 1.40765\n",
      "[5]\ttrain's multi_logloss: 1.35134\tvalid's multi_logloss: 1.39689\n",
      "[6]\ttrain's multi_logloss: 1.33454\tvalid's multi_logloss: 1.38846\n",
      "[7]\ttrain's multi_logloss: 1.31915\tvalid's multi_logloss: 1.38141\n",
      "[8]\ttrain's multi_logloss: 1.30533\tvalid's multi_logloss: 1.37572\n",
      "[9]\ttrain's multi_logloss: 1.29231\tvalid's multi_logloss: 1.37087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.366590:  20%|#############4                                                     | 1/5 [00:00<00:03,  1.11it/s]\u001b[32m[I 2021-03-23 23:25:19,998]\u001b[0m Trial 60 finished with value: 1.3665900072538673 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 1.3665900072538673.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.366590:  20%|#############4                                                     | 1/5 [00:00<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.28037\tvalid's multi_logloss: 1.36659\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.28037\tvalid's multi_logloss: 1.36659\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44995\tvalid's multi_logloss: 1.45988\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41763\tvalid's multi_logloss: 1.43951\n",
      "[3]\ttrain's multi_logloss: 1.39085\tvalid's multi_logloss: 1.42266\n",
      "[4]\ttrain's multi_logloss: 1.36819\tvalid's multi_logloss: 1.40963\n",
      "[5]\ttrain's multi_logloss: 1.34825\tvalid's multi_logloss: 1.39852\n",
      "[6]\ttrain's multi_logloss: 1.33073\tvalid's multi_logloss: 1.38996\n",
      "[7]\ttrain's multi_logloss: 1.31487\tvalid's multi_logloss: 1.38313\n",
      "[8]\ttrain's multi_logloss: 1.30054\tvalid's multi_logloss: 1.37745\n",
      "[9]\ttrain's multi_logloss: 1.287\tvalid's multi_logloss: 1.37222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.366590:  40%|##########################8                                        | 2/5 [00:01<00:02,  1.09it/s]\u001b[32m[I 2021-03-23 23:25:20,930]\u001b[0m Trial 61 finished with value: 1.367968214412765 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 1.3665900072538673.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.366590:  40%|##########################8                                        | 2/5 [00:01<00:02,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.27447\tvalid's multi_logloss: 1.36797\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.27447\tvalid's multi_logloss: 1.36797\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.45206\tvalid's multi_logloss: 1.45919\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.42161\tvalid's multi_logloss: 1.43772\n",
      "[3]\ttrain's multi_logloss: 1.39619\tvalid's multi_logloss: 1.4208\n",
      "[4]\ttrain's multi_logloss: 1.37454\tvalid's multi_logloss: 1.40734\n",
      "[5]\ttrain's multi_logloss: 1.35589\tvalid's multi_logloss: 1.39706\n",
      "[6]\ttrain's multi_logloss: 1.33957\tvalid's multi_logloss: 1.38837\n",
      "[7]\ttrain's multi_logloss: 1.32467\tvalid's multi_logloss: 1.38093\n",
      "[8]\ttrain's multi_logloss: 1.31145\tvalid's multi_logloss: 1.37498\n",
      "[9]\ttrain's multi_logloss: 1.29917\tvalid's multi_logloss: 1.37031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.366199:  60%|########################################1                          | 3/5 [00:02<00:01,  1.10it/s]\u001b[32m[I 2021-03-23 23:25:21,830]\u001b[0m Trial 62 finished with value: 1.366199072614477 and parameters: {'min_child_samples': 100}. Best is trial 62 with value: 1.366199072614477.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.366199:  60%|########################################1                          | 3/5 [00:02<00:01,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.28801\tvalid's multi_logloss: 1.3662\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.28801\tvalid's multi_logloss: 1.3662\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44872\tvalid's multi_logloss: 1.46022\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.41585\tvalid's multi_logloss: 1.4388\n",
      "[3]\ttrain's multi_logloss: 1.38841\tvalid's multi_logloss: 1.42272\n",
      "[4]\ttrain's multi_logloss: 1.36479\tvalid's multi_logloss: 1.40993\n",
      "[5]\ttrain's multi_logloss: 1.34404\tvalid's multi_logloss: 1.39976\n",
      "[6]\ttrain's multi_logloss: 1.32595\tvalid's multi_logloss: 1.39118\n",
      "[7]\ttrain's multi_logloss: 1.30933\tvalid's multi_logloss: 1.38439\n",
      "[8]\ttrain's multi_logloss: 1.2942\tvalid's multi_logloss: 1.3787\n",
      "[9]\ttrain's multi_logloss: 1.28004\tvalid's multi_logloss: 1.37431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.366199:  80%|#####################################################6             | 4/5 [00:03<00:00,  1.09it/s]\u001b[32m[I 2021-03-23 23:25:22,767]\u001b[0m Trial 63 finished with value: 1.3702535068541863 and parameters: {'min_child_samples': 5}. Best is trial 62 with value: 1.366199072614477.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.366199:  80%|#####################################################6             | 4/5 [00:03<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.26663\tvalid's multi_logloss: 1.37025\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.26663\tvalid's multi_logloss: 1.37025\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31635, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -2.052589\n",
      "[LightGBM] [Info] Start training from score -1.854069\n",
      "[LightGBM] [Info] Start training from score -1.180078\n",
      "[LightGBM] [Info] Start training from score -2.480459\n",
      "[LightGBM] [Info] Start training from score -1.126889\n",
      "[1]\ttrain's multi_logloss: 1.44888\tvalid's multi_logloss: 1.45967\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's multi_logloss: 1.4163\tvalid's multi_logloss: 1.43867\n",
      "[3]\ttrain's multi_logloss: 1.38915\tvalid's multi_logloss: 1.42226\n",
      "[4]\ttrain's multi_logloss: 1.36567\tvalid's multi_logloss: 1.40939\n",
      "[5]\ttrain's multi_logloss: 1.34535\tvalid's multi_logloss: 1.39914\n",
      "[6]\ttrain's multi_logloss: 1.32725\tvalid's multi_logloss: 1.39064\n",
      "[7]\ttrain's multi_logloss: 1.31099\tvalid's multi_logloss: 1.38355\n",
      "[8]\ttrain's multi_logloss: 1.29618\tvalid's multi_logloss: 1.37798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.366199: 100%|###################################################################| 5/5 [00:04<00:00,  1.07it/s]\u001b[32m[I 2021-03-23 23:25:23,740]\u001b[0m Trial 64 finished with value: 1.3694459284413774 and parameters: {'min_child_samples': 10}. Best is trial 62 with value: 1.366199072614477.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.366199: 100%|###################################################################| 5/5 [00:04<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttrain's multi_logloss: 1.28225\tvalid's multi_logloss: 1.37307\n",
      "[10]\ttrain's multi_logloss: 1.26947\tvalid's multi_logloss: 1.36945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttrain's multi_logloss: 1.26947\tvalid's multi_logloss: 1.36945\n",
      "accuracy: 0.42407257172357843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set the data to fit model\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train) \n",
    "\n",
    "# LightGBM parameters\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass', \n",
    "        'num_class': 5,           \n",
    "        'metric': 'multi_logloss', \n",
    "        'max_depth' : 10,\n",
    "}\n",
    "\n",
    "evaluation_results = {}      \n",
    "# make model\n",
    "model = lgb.train(params,\n",
    "                  num_boost_round=10,\n",
    "                  train_set=lgb_train, \n",
    "                  valid_sets=[lgb_train, lgb_eval], \n",
    "                  evals_result=evaluation_results,\n",
    "                  early_stopping_rounds=20,\n",
    "                  valid_names=['train', 'valid'],        \n",
    "                  )\n",
    "\n",
    "\n",
    "# predict by test data\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# calcurate accuracy\n",
    "accuracy = sum(y_test == y_pred_max) / len(y_test)\n",
    "print('accuracy:', accuracy)\n",
    "    \n",
    "optimum_boost_rounds = model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learning process\n",
    "plt.plot(evaluation_results['train']['multi_logloss'], label='train')\n",
    "plt.plot(evaluation_results['valid']['multi_logloss'], label='valid')\n",
    "plt.ylabel('Log loss')\n",
    "plt.xlabel('Boosting round')\n",
    "plt.title('Training performance')\n",
    "plt.legend()\n",
    "plt.savefig('cv_logloss.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NEWJobHunt</td>\n",
       "      <td>0.069333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>JobSeek</td>\n",
       "      <td>0.041067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NEWPurchaseResearch</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ConvertedComp</td>\n",
       "      <td>0.034933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DevType</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  importance\n",
       "28           NEWJobHunt    0.069333\n",
       "18              JobSeek    0.041067\n",
       "35  NEWPurchaseResearch    0.036000\n",
       "6         ConvertedComp    0.034933\n",
       "12              DevType    0.034400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the importance features table\n",
    "cols = list(X.columns)       # list of feautures\n",
    "f_importance = np.array(model.feature_importance()) # importance feature\n",
    "f_importance = f_importance / np.sum(f_importance)  \n",
    "df_importance = pd.DataFrame({'feature':cols, 'importance':f_importance})\n",
    "df_importance = df_importance.sort_values('importance', ascending=False) # sort\n",
    "display(df_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the importance features gragh\n",
    "def plot_feature_importance(df): \n",
    "    n_features = len(df)                              \n",
    "    df_plot = df.sort_values('importance')            \n",
    "    f_importance_plot = df_plot['importance'].values  \n",
    "    plt.barh(range(n_features), f_importance_plot, align='center') \n",
    "    cols_plot = df_plot['feature'].values            \n",
    "    plt.yticks(np.arange(n_features), cols_plot)     \n",
    "    plt.xlabel('Feature importance')                  \n",
    "    plt.ylabel('Feature')                             \n",
    "\n",
    "plot_feature_importance(df_importance[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Make the table that explain the influence between Job satisfaction and NEWJobHunt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_NaN = df.dropna(subset=['NEWJobHunt'])\n",
    "df_Just_because = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Just because')]\n",
    "df_Having_a_bad_day = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Having a bad day')]\n",
    "df_wider_networke = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('wider network')]\n",
    "df_Curious_about_other_opportunities = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Curious about other opportunities')]\n",
    "df_Better_compensation = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Better compensation')]\n",
    "df_Trouble_with_my_teammatesn = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Trouble with my teammates')]\n",
    "df_Trouble_with_my_direct_manager = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Trouble with my direct manager')]\n",
    "df_Trouble_with_leadership_at_my_company = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Trouble with leadership at my company')]\n",
    "df_Better_work_life_balance = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Better work/life balance')]\n",
    "df_Wanting_to_work_with_new_technologies = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Wanting to work with new technologies')]\n",
    "df_Growth_or_leadership_opportunities = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Growth or leadership opportunities')]\n",
    "df_Looking_to_relocate = df_drop_NaN[df_drop_NaN['NEWJobHunt'].str.contains('Looking to relocate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list =[df_Just_because, df_Having_a_bad_day,df_wider_networke, df_Curious_about_other_opportunities, df_Better_compensation, df_Trouble_with_my_teammatesn, \\\n",
    "          df_Trouble_with_my_direct_manager, df_Trouble_with_leadership_at_my_company, df_Better_work_life_balance, \\\n",
    "          df_Wanting_to_work_with_new_technologies, df_Growth_or_leadership_opportunities, df_Looking_to_relocate] \n",
    "\n",
    "index_list = [\"Just because\", \"Having a bad day (or week or month) at work\", \"Wanting to share accomplishments with a wider network\", \\\n",
    "            \"Curious about other opportunities\", \"Better compensation\", \"Trouble with my teammates\", \"Trouble with my direct manager\", \\\n",
    "            \"Trouble with leadership at my company\", \"Better work/life balance\", \"Wanting to work with new technologies\", \\\n",
    "            \"Growth or leadership opportunities\", \"Looking to relocate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neither satisfied nor dissatisfied</th>\n",
       "      <th>Slightly dissatisfied</th>\n",
       "      <th>Slightly satisfied</th>\n",
       "      <th>Very dissatisfied</th>\n",
       "      <th>Very satisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Just because</th>\n",
       "      <td>0.133375</td>\n",
       "      <td>0.140177</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.065141</td>\n",
       "      <td>0.321171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Having a bad day (or week or month) at work</th>\n",
       "      <td>0.144463</td>\n",
       "      <td>0.239416</td>\n",
       "      <td>0.325401</td>\n",
       "      <td>0.089213</td>\n",
       "      <td>0.201507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanting to share accomplishments with a wider network</th>\n",
       "      <td>0.164824</td>\n",
       "      <td>0.194547</td>\n",
       "      <td>0.320806</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>0.233112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curious about other opportunities</th>\n",
       "      <td>0.125373</td>\n",
       "      <td>0.163391</td>\n",
       "      <td>0.334644</td>\n",
       "      <td>0.069123</td>\n",
       "      <td>0.307470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Better compensation</th>\n",
       "      <td>0.131690</td>\n",
       "      <td>0.169531</td>\n",
       "      <td>0.328014</td>\n",
       "      <td>0.076629</td>\n",
       "      <td>0.294136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trouble with my teammates</th>\n",
       "      <td>0.116891</td>\n",
       "      <td>0.159646</td>\n",
       "      <td>0.282856</td>\n",
       "      <td>0.098568</td>\n",
       "      <td>0.342039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trouble with my direct manager</th>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.163431</td>\n",
       "      <td>0.274993</td>\n",
       "      <td>0.110258</td>\n",
       "      <td>0.342075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trouble with leadership at my company</th>\n",
       "      <td>0.114539</td>\n",
       "      <td>0.200146</td>\n",
       "      <td>0.281008</td>\n",
       "      <td>0.106872</td>\n",
       "      <td>0.297435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Better work/life balance</th>\n",
       "      <td>0.143013</td>\n",
       "      <td>0.164620</td>\n",
       "      <td>0.316597</td>\n",
       "      <td>0.083113</td>\n",
       "      <td>0.292658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanting to work with new technologies</th>\n",
       "      <td>0.134688</td>\n",
       "      <td>0.174522</td>\n",
       "      <td>0.321766</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.290884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Growth or leadership opportunities</th>\n",
       "      <td>0.127095</td>\n",
       "      <td>0.167981</td>\n",
       "      <td>0.311225</td>\n",
       "      <td>0.080187</td>\n",
       "      <td>0.313512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Looking to relocate</th>\n",
       "      <td>0.130796</td>\n",
       "      <td>0.154217</td>\n",
       "      <td>0.327132</td>\n",
       "      <td>0.075550</td>\n",
       "      <td>0.312305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Neither satisfied nor dissatisfied  \\\n",
       "Just because                                                                  0.133375   \n",
       "Having a bad day (or week or month) at work                                   0.144463   \n",
       "Wanting to share accomplishments with a wider n...                            0.164824   \n",
       "Curious about other opportunities                                             0.125373   \n",
       "Better compensation                                                           0.131690   \n",
       "Trouble with my teammates                                                     0.116891   \n",
       "Trouble with my direct manager                                                0.109244   \n",
       "Trouble with leadership at my company                                         0.114539   \n",
       "Better work/life balance                                                      0.143013   \n",
       "Wanting to work with new technologies                                         0.134688   \n",
       "Growth or leadership opportunities                                            0.127095   \n",
       "Looking to relocate                                                           0.130796   \n",
       "\n",
       "                                                    Slightly dissatisfied  \\\n",
       "Just because                                                     0.140177   \n",
       "Having a bad day (or week or month) at work                      0.239416   \n",
       "Wanting to share accomplishments with a wider n...               0.194547   \n",
       "Curious about other opportunities                                0.163391   \n",
       "Better compensation                                              0.169531   \n",
       "Trouble with my teammates                                        0.159646   \n",
       "Trouble with my direct manager                                   0.163431   \n",
       "Trouble with leadership at my company                            0.200146   \n",
       "Better work/life balance                                         0.164620   \n",
       "Wanting to work with new technologies                            0.174522   \n",
       "Growth or leadership opportunities                               0.167981   \n",
       "Looking to relocate                                              0.154217   \n",
       "\n",
       "                                                    Slightly satisfied  \\\n",
       "Just because                                                  0.340136   \n",
       "Having a bad day (or week or month) at work                   0.325401   \n",
       "Wanting to share accomplishments with a wider n...            0.320806   \n",
       "Curious about other opportunities                             0.334644   \n",
       "Better compensation                                           0.328014   \n",
       "Trouble with my teammates                                     0.282856   \n",
       "Trouble with my direct manager                                0.274993   \n",
       "Trouble with leadership at my company                         0.281008   \n",
       "Better work/life balance                                      0.316597   \n",
       "Wanting to work with new technologies                         0.321766   \n",
       "Growth or leadership opportunities                            0.311225   \n",
       "Looking to relocate                                           0.327132   \n",
       "\n",
       "                                                    Very dissatisfied  \\\n",
       "Just because                                                 0.065141   \n",
       "Having a bad day (or week or month) at work                  0.089213   \n",
       "Wanting to share accomplishments with a wider n...           0.086711   \n",
       "Curious about other opportunities                            0.069123   \n",
       "Better compensation                                          0.076629   \n",
       "Trouble with my teammates                                    0.098568   \n",
       "Trouble with my direct manager                               0.110258   \n",
       "Trouble with leadership at my company                        0.106872   \n",
       "Better work/life balance                                     0.083113   \n",
       "Wanting to work with new technologies                        0.078140   \n",
       "Growth or leadership opportunities                           0.080187   \n",
       "Looking to relocate                                          0.075550   \n",
       "\n",
       "                                                    Very satisfied  \n",
       "Just because                                              0.321171  \n",
       "Having a bad day (or week or month) at work               0.201507  \n",
       "Wanting to share accomplishments with a wider n...        0.233112  \n",
       "Curious about other opportunities                         0.307470  \n",
       "Better compensation                                       0.294136  \n",
       "Trouble with my teammates                                 0.342039  \n",
       "Trouble with my direct manager                            0.342075  \n",
       "Trouble with leadership at my company                     0.297435  \n",
       "Better work/life balance                                  0.292658  \n",
       "Wanting to work with new technologies                     0.290884  \n",
       "Growth or leadership opportunities                        0.313512  \n",
       "Looking to relocate                                       0.312305  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the table\n",
    "def sort_df(df):\n",
    "    table = { key: (df['JobSat']==key).sum() for key in set(df['JobSat'])} \n",
    "    values = [table[\"Very satisfied\"], table[\"Slightly satisfied\"], table[\"Neither satisfied nor dissatisfied\"], table[\"Slightly dissatisfied\"], table[\"Very dissatisfied\"]]/(table[\"Very satisfied\"] + table[\"Slightly satisfied\"] + table[\"Neither satisfied nor dissatisfied\"] + table[\"Slightly dissatisfied\"] + table[\"Very dissatisfied\"])\n",
    "    label = [\"Very satisfied\", \"Slightly satisfied\", \"Neither satisfied nor dissatisfied\", \"Slightly dissatisfied\", \"Very dissatisfied\"]\n",
    "    \n",
    "    return pd.Series(values, index = label)\n",
    "\n",
    "df_summary = pd.DataFrame({\"Very satisfied\":[]})\n",
    "for i in df_list:\n",
    "    df_temp = sort_df(i)\n",
    "    df_summary = df_summary.append(df_temp, ignore_index=True, sort=True)\n",
    "    \n",
    "df_summary.index = index_list\n",
    "df_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_avilen)",
   "language": "python",
   "name": "conda_avilen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
